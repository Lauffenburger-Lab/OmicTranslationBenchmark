{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913b1b9d",
   "metadata": {},
   "source": [
    "# Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c35c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from scipy.stats import mannwhitneyu\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import umap\n",
    "\n",
    "from models import SimpleEncoder,Decoder,PriorDiscriminator,LocalDiscriminator\n",
    "from evaluationUtils import r_square,get_cindex,pearson_r,pseudoAccuracy\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4d73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec26083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train generators\n",
    "def getSamples(N, batchSize):\n",
    "    order = np.random.permutation(N)\n",
    "    outList = []\n",
    "    while len(order)>0:\n",
    "        outList.append(order[0:batchSize])\n",
    "        order = order[batchSize:]\n",
    "    return outList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55e6136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniformLoss(curState, dataIndex, z, targetMin = 0, targetMax = 1.0, maxConstraintFactor = 10):\n",
    "    data = curState.detach().clone()\n",
    "    data[dataIndex, :] = z\n",
    "\n",
    "    targetMean = (targetMax-targetMin)/2\n",
    "    targetVar= (targetMax-targetMin)**2/12\n",
    "\n",
    "    factor = 1\n",
    "    meanFactor = factor\n",
    "    varFactor = factor\n",
    "    minFactor = factor\n",
    "    maxFactor = factor\n",
    "    maxConstraintFactor = factor * maxConstraintFactor\n",
    "\n",
    "    nodeMean = torch.mean(data, dim=0)\n",
    "    nodeVar = torch.mean(torch.square(data-nodeMean), dim=0)\n",
    "    maxVal, _ = torch.max(data, dim=0)\n",
    "    minVal, _ = torch.min(data, dim=0)\n",
    "\n",
    "    meanLoss = meanFactor * torch.sum(torch.square(nodeMean - targetMean))\n",
    "    varLoss =  varFactor * torch.sum(torch.square(nodeVar - targetVar))\n",
    "    maxLoss = maxFactor * torch.sum(torch.square(maxVal - targetMax))\n",
    "    minloss = minFactor * torch.sum(torch.square(minVal- targetMin))\n",
    "    maxConstraint = -maxConstraintFactor * torch.sum(maxVal[maxVal.detach()<=0]) #max value should never be negative\n",
    "\n",
    "    loss = meanLoss + varLoss + minloss + maxLoss + maxConstraint\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5439b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalLoss(curState, dataIndex, z, targetMin = -5.01, targetMax = 5.01, maxConstraintFactor = 10):\n",
    "    data = curState.detach().clone()\n",
    "    data[dataIndex, :] = z\n",
    "\n",
    "    targetMean = 0.\n",
    "    targetVar= 1.\n",
    "\n",
    "    factor = 1\n",
    "    meanFactor = factor\n",
    "    varFactor = factor\n",
    "    minFactor = factor\n",
    "    maxFactor = factor\n",
    "    maxConstraintFactor = factor * maxConstraintFactor\n",
    "\n",
    "    nodeMean = torch.mean(data, dim=0)\n",
    "    nodeVar = torch.mean(torch.square(data-nodeMean), dim=0)\n",
    "    maxVal, _ = torch.max(data, dim=0)\n",
    "    minVal, _ = torch.min(data, dim=0)\n",
    "\n",
    "    meanLoss = meanFactor * torch.sum(torch.square(nodeMean - targetMean))\n",
    "    varLoss =  varFactor * torch.sum(torch.square(nodeVar - targetVar))\n",
    "    maxLoss = maxFactor * torch.sum(torch.square(maxVal - targetMax))\n",
    "    minloss = minFactor * torch.sum(torch.square(minVal- targetMin))\n",
    "    maxConstraint = -maxConstraintFactor * torch.sum(maxVal[maxVal.detach()<=0]) #max value should never be negative\n",
    "\n",
    "    loss = meanLoss + varLoss + minloss + maxLoss + maxConstraint\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8d9cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kl_loss(s1,s2,m1,m2):\n",
    "#     l = torch.log(s2/s1 + 1e-6) + (s1**2 +(m1-m2)**2)/(2*s2**2 + 1e-6) - 0.5\n",
    "#     return l.mean()\n",
    "def kl_loss(m,s):\n",
    "    l = torch.square(m) + torch.square(s) - torch.log(s + 1e-04) - 0.5\n",
    "    return l.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f97e64",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9ca653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>23</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>39</th>\n",
       "      <th>47</th>\n",
       "      <th>102</th>\n",
       "      <th>128</th>\n",
       "      <th>142</th>\n",
       "      <th>154</th>\n",
       "      <th>...</th>\n",
       "      <th>94239</th>\n",
       "      <th>116832</th>\n",
       "      <th>124583</th>\n",
       "      <th>147179</th>\n",
       "      <th>148022</th>\n",
       "      <th>200081</th>\n",
       "      <th>200734</th>\n",
       "      <th>256364</th>\n",
       "      <th>375346</th>\n",
       "      <th>388650</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCL001_HT29_24H:BRD-K42991516:10</th>\n",
       "      <td>0.266452</td>\n",
       "      <td>-0.250874</td>\n",
       "      <td>-0.854204</td>\n",
       "      <td>-0.041545</td>\n",
       "      <td>0.204450</td>\n",
       "      <td>0.709800</td>\n",
       "      <td>-0.328601</td>\n",
       "      <td>-0.498116</td>\n",
       "      <td>-1.454481</td>\n",
       "      <td>0.506321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536235</td>\n",
       "      <td>0.024452</td>\n",
       "      <td>0.928558</td>\n",
       "      <td>-0.453246</td>\n",
       "      <td>-0.140290</td>\n",
       "      <td>0.205065</td>\n",
       "      <td>1.148706</td>\n",
       "      <td>-1.933820</td>\n",
       "      <td>1.966937</td>\n",
       "      <td>-0.159919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCL001_HT29_24H:BRD-K50817946:10</th>\n",
       "      <td>6.074023</td>\n",
       "      <td>-0.524075</td>\n",
       "      <td>-0.635742</td>\n",
       "      <td>2.014629</td>\n",
       "      <td>-3.747274</td>\n",
       "      <td>2.109600</td>\n",
       "      <td>0.847576</td>\n",
       "      <td>-2.732549</td>\n",
       "      <td>-5.729352</td>\n",
       "      <td>2.164091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447939</td>\n",
       "      <td>1.543649</td>\n",
       "      <td>-3.775020</td>\n",
       "      <td>1.827991</td>\n",
       "      <td>-0.088051</td>\n",
       "      <td>0.382848</td>\n",
       "      <td>1.400255</td>\n",
       "      <td>-3.087269</td>\n",
       "      <td>1.392148</td>\n",
       "      <td>1.027263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOG002_A549_24H:BRD-K28296557-005-14-6:3.33</th>\n",
       "      <td>3.092555</td>\n",
       "      <td>1.760324</td>\n",
       "      <td>0.045857</td>\n",
       "      <td>-0.267738</td>\n",
       "      <td>-5.237659</td>\n",
       "      <td>-1.254134</td>\n",
       "      <td>-1.197927</td>\n",
       "      <td>-2.120804</td>\n",
       "      <td>-2.096229</td>\n",
       "      <td>0.799317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253642</td>\n",
       "      <td>-0.461737</td>\n",
       "      <td>-2.344703</td>\n",
       "      <td>1.581582</td>\n",
       "      <td>4.007076</td>\n",
       "      <td>-0.203330</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>1.502107</td>\n",
       "      <td>1.281574</td>\n",
       "      <td>0.450898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSBIO001_MCF7_24H:BRD-K77888550:9.5278</th>\n",
       "      <td>-1.680236</td>\n",
       "      <td>1.174203</td>\n",
       "      <td>0.295703</td>\n",
       "      <td>0.555778</td>\n",
       "      <td>0.136969</td>\n",
       "      <td>-1.507160</td>\n",
       "      <td>-0.068983</td>\n",
       "      <td>-0.468983</td>\n",
       "      <td>-1.894113</td>\n",
       "      <td>-0.035792</td>\n",
       "      <td>...</td>\n",
       "      <td>1.204646</td>\n",
       "      <td>-0.688365</td>\n",
       "      <td>-1.042315</td>\n",
       "      <td>2.571737</td>\n",
       "      <td>-0.085614</td>\n",
       "      <td>-3.472259</td>\n",
       "      <td>1.436653</td>\n",
       "      <td>-1.054814</td>\n",
       "      <td>1.873788</td>\n",
       "      <td>1.680525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSBIO001_NPC_24H:BRD-K09069264:10.2084</th>\n",
       "      <td>-1.401400</td>\n",
       "      <td>0.308703</td>\n",
       "      <td>1.178614</td>\n",
       "      <td>-2.114849</td>\n",
       "      <td>-0.020324</td>\n",
       "      <td>-0.393869</td>\n",
       "      <td>-2.599080</td>\n",
       "      <td>-0.983008</td>\n",
       "      <td>-0.063675</td>\n",
       "      <td>-0.549799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349096</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.356195</td>\n",
       "      <td>0.638253</td>\n",
       "      <td>0.862676</td>\n",
       "      <td>-0.106953</td>\n",
       "      <td>1.115011</td>\n",
       "      <td>2.205899</td>\n",
       "      <td>-0.306434</td>\n",
       "      <td>1.101611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_MCF7_24H:BRD-K30867024:10</th>\n",
       "      <td>-0.228277</td>\n",
       "      <td>-0.574911</td>\n",
       "      <td>0.545074</td>\n",
       "      <td>1.320753</td>\n",
       "      <td>-0.102422</td>\n",
       "      <td>1.058099</td>\n",
       "      <td>0.366014</td>\n",
       "      <td>-1.520461</td>\n",
       "      <td>-0.004073</td>\n",
       "      <td>-0.637326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057771</td>\n",
       "      <td>-0.660938</td>\n",
       "      <td>-1.952505</td>\n",
       "      <td>0.395937</td>\n",
       "      <td>1.790094</td>\n",
       "      <td>1.072335</td>\n",
       "      <td>1.657834</td>\n",
       "      <td>1.445156</td>\n",
       "      <td>2.031223</td>\n",
       "      <td>0.026611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL002_A375_24H:BRD-K10749593:20</th>\n",
       "      <td>4.415511</td>\n",
       "      <td>0.608378</td>\n",
       "      <td>1.604217</td>\n",
       "      <td>-0.911175</td>\n",
       "      <td>-2.611416</td>\n",
       "      <td>-1.742975</td>\n",
       "      <td>-2.500287</td>\n",
       "      <td>-2.503129</td>\n",
       "      <td>-3.472708</td>\n",
       "      <td>3.008501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916562</td>\n",
       "      <td>-1.403280</td>\n",
       "      <td>0.479218</td>\n",
       "      <td>4.528471</td>\n",
       "      <td>1.701896</td>\n",
       "      <td>0.141621</td>\n",
       "      <td>1.953133</td>\n",
       "      <td>-1.480089</td>\n",
       "      <td>1.549125</td>\n",
       "      <td>1.414482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL002_MCF7_24H:BRD-K14002526:20</th>\n",
       "      <td>1.311693</td>\n",
       "      <td>1.834785</td>\n",
       "      <td>1.277888</td>\n",
       "      <td>-0.224320</td>\n",
       "      <td>-0.365258</td>\n",
       "      <td>0.209443</td>\n",
       "      <td>0.166746</td>\n",
       "      <td>-2.112468</td>\n",
       "      <td>-0.870127</td>\n",
       "      <td>-0.083894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894919</td>\n",
       "      <td>-0.707055</td>\n",
       "      <td>0.519019</td>\n",
       "      <td>0.916627</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>0.126153</td>\n",
       "      <td>2.277303</td>\n",
       "      <td>-1.870382</td>\n",
       "      <td>1.021850</td>\n",
       "      <td>1.199542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_HT29_24H:BRD-K11624501:9.99164</th>\n",
       "      <td>1.540175</td>\n",
       "      <td>-0.196926</td>\n",
       "      <td>-0.094410</td>\n",
       "      <td>-1.951286</td>\n",
       "      <td>-2.848082</td>\n",
       "      <td>-2.478519</td>\n",
       "      <td>-1.257487</td>\n",
       "      <td>-1.247405</td>\n",
       "      <td>-4.006328</td>\n",
       "      <td>-0.362494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371798</td>\n",
       "      <td>3.735393</td>\n",
       "      <td>2.011243</td>\n",
       "      <td>1.693114</td>\n",
       "      <td>2.924200</td>\n",
       "      <td>2.535851</td>\n",
       "      <td>1.861230</td>\n",
       "      <td>-3.021530</td>\n",
       "      <td>0.127304</td>\n",
       "      <td>0.980487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_HCC515_24H:BRD-K48853221:10</th>\n",
       "      <td>3.427549</td>\n",
       "      <td>0.592761</td>\n",
       "      <td>-0.633423</td>\n",
       "      <td>-1.034512</td>\n",
       "      <td>1.337766</td>\n",
       "      <td>-0.138157</td>\n",
       "      <td>-1.700268</td>\n",
       "      <td>-0.425595</td>\n",
       "      <td>-1.978633</td>\n",
       "      <td>0.559278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.677538</td>\n",
       "      <td>-0.900451</td>\n",
       "      <td>0.067572</td>\n",
       "      <td>-0.153004</td>\n",
       "      <td>5.329951</td>\n",
       "      <td>-0.593923</td>\n",
       "      <td>0.100499</td>\n",
       "      <td>0.381238</td>\n",
       "      <td>0.816859</td>\n",
       "      <td>0.400983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13699 rows × 978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   16        23        25  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10             0.266452 -0.250874 -0.854204   \n",
       "PCL001_HT29_24H:BRD-K50817946:10             6.074023 -0.524075 -0.635742   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33  3.092555  1.760324  0.045857   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -1.680236  1.174203  0.295703   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084     -1.401400  0.308703  1.178614   \n",
       "...                                               ...       ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10         -0.228277 -0.574911  0.545074   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20          4.415511  0.608378  1.604217   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20          1.311693  1.834785  1.277888   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164     1.540175 -0.196926 -0.094410   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10        3.427549  0.592761 -0.633423   \n",
       "\n",
       "                                                   30        39        47  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10            -0.041545  0.204450  0.709800   \n",
       "PCL001_HT29_24H:BRD-K50817946:10             2.014629 -3.747274  2.109600   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33 -0.267738 -5.237659 -1.254134   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278      0.555778  0.136969 -1.507160   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084     -2.114849 -0.020324 -0.393869   \n",
       "...                                               ...       ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10          1.320753 -0.102422  1.058099   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20         -0.911175 -2.611416 -1.742975   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20         -0.224320 -0.365258  0.209443   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164    -1.951286 -2.848082 -2.478519   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10       -1.034512  1.337766 -0.138157   \n",
       "\n",
       "                                                  102       128       142  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10            -0.328601 -0.498116 -1.454481   \n",
       "PCL001_HT29_24H:BRD-K50817946:10             0.847576 -2.732549 -5.729352   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33 -1.197927 -2.120804 -2.096229   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -0.068983 -0.468983 -1.894113   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084     -2.599080 -0.983008 -0.063675   \n",
       "...                                               ...       ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10          0.366014 -1.520461 -0.004073   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20         -2.500287 -2.503129 -3.472708   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20          0.166746 -2.112468 -0.870127   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164    -1.257487 -1.247405 -4.006328   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10       -1.700268 -0.425595 -1.978633   \n",
       "\n",
       "                                                  154  ...     94239  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10             0.506321  ...  0.536235   \n",
       "PCL001_HT29_24H:BRD-K50817946:10             2.164091  ...  0.447939   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33  0.799317  ...  0.253642   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -0.035792  ...  1.204646   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084     -0.549799  ...  0.349096   \n",
       "...                                               ...  ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10         -0.637326  ... -0.057771   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20          3.008501  ...  0.916562   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20         -0.083894  ...  0.894919   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164    -0.362494  ... -0.371798   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10        0.559278  ... -0.677538   \n",
       "\n",
       "                                               116832    124583    147179  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10             0.024452  0.928558 -0.453246   \n",
       "PCL001_HT29_24H:BRD-K50817946:10             1.543649 -3.775020  1.827991   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33 -0.461737 -2.344703  1.581582   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -0.688365 -1.042315  2.571737   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084      0.017305  0.356195  0.638253   \n",
       "...                                               ...       ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10         -0.660938 -1.952505  0.395937   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20         -1.403280  0.479218  4.528471   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20         -0.707055  0.519019  0.916627   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164     3.735393  2.011243  1.693114   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10       -0.900451  0.067572 -0.153004   \n",
       "\n",
       "                                               148022    200081    200734  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10            -0.140290  0.205065  1.148706   \n",
       "PCL001_HT29_24H:BRD-K50817946:10            -0.088051  0.382848  1.400255   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33  4.007076 -0.203330  0.715596   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -0.085614 -3.472259  1.436653   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084      0.862676 -0.106953  1.115011   \n",
       "...                                               ...       ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10          1.790094  1.072335  1.657834   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20          1.701896  0.141621  1.953133   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20          0.710227  0.126153  2.277303   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164     2.924200  2.535851  1.861230   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10        5.329951 -0.593923  0.100499   \n",
       "\n",
       "                                               256364    375346    388650  \n",
       "PCL001_HT29_24H:BRD-K42991516:10            -1.933820  1.966937 -0.159919  \n",
       "PCL001_HT29_24H:BRD-K50817946:10            -3.087269  1.392148  1.027263  \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33  1.502107  1.281574  0.450898  \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -1.054814  1.873788  1.680525  \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084      2.205899 -0.306434  1.101611  \n",
       "...                                               ...       ...       ...  \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10          1.445156  2.031223  0.026611  \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20         -1.480089  1.549125  1.414482  \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20         -1.870382  1.021850  1.199542  \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164    -3.021530  0.127304  0.980487  \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10        0.381238  0.816859  0.400983  \n",
       "\n",
       "[13699 rows x 978 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gex data \n",
    "cmap = pd.read_csv('../preprocessing/preprocessed_data/all_cmap_landmarks.csv',index_col=0)\n",
    "gene_size = len(cmap.columns)\n",
    "X = cmap.values\n",
    "display(cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65cc95ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>23</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>39</th>\n",
       "      <th>47</th>\n",
       "      <th>102</th>\n",
       "      <th>128</th>\n",
       "      <th>142</th>\n",
       "      <th>154</th>\n",
       "      <th>...</th>\n",
       "      <th>94239</th>\n",
       "      <th>116832</th>\n",
       "      <th>124583</th>\n",
       "      <th>147179</th>\n",
       "      <th>148022</th>\n",
       "      <th>200081</th>\n",
       "      <th>200734</th>\n",
       "      <th>256364</th>\n",
       "      <th>375346</th>\n",
       "      <th>388650</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OFL001_A549_96H:G15</th>\n",
       "      <td>1.854175</td>\n",
       "      <td>1.868439</td>\n",
       "      <td>-0.140405</td>\n",
       "      <td>-0.278911</td>\n",
       "      <td>0.396597</td>\n",
       "      <td>0.334116</td>\n",
       "      <td>0.473704</td>\n",
       "      <td>-0.565553</td>\n",
       "      <td>1.372410</td>\n",
       "      <td>1.181299</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252141</td>\n",
       "      <td>-0.291923</td>\n",
       "      <td>1.193942</td>\n",
       "      <td>0.978987</td>\n",
       "      <td>2.381282</td>\n",
       "      <td>-1.065447</td>\n",
       "      <td>1.174847</td>\n",
       "      <td>-0.885704</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.216700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFL001_MCF7_96H:J10</th>\n",
       "      <td>0.081511</td>\n",
       "      <td>0.651525</td>\n",
       "      <td>-0.205014</td>\n",
       "      <td>0.054704</td>\n",
       "      <td>0.726742</td>\n",
       "      <td>-0.126017</td>\n",
       "      <td>0.200712</td>\n",
       "      <td>0.915557</td>\n",
       "      <td>0.780285</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341261</td>\n",
       "      <td>0.405606</td>\n",
       "      <td>-0.054713</td>\n",
       "      <td>0.264261</td>\n",
       "      <td>-0.096964</td>\n",
       "      <td>0.752965</td>\n",
       "      <td>-0.249324</td>\n",
       "      <td>-1.176310</td>\n",
       "      <td>0.282062</td>\n",
       "      <td>-0.212717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABY001_NCIH1975_XH:CMAP-000:-666:3</th>\n",
       "      <td>0.543459</td>\n",
       "      <td>1.647965</td>\n",
       "      <td>-1.731661</td>\n",
       "      <td>0.319534</td>\n",
       "      <td>1.078192</td>\n",
       "      <td>0.602553</td>\n",
       "      <td>0.323291</td>\n",
       "      <td>0.787790</td>\n",
       "      <td>0.888264</td>\n",
       "      <td>1.532468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704732</td>\n",
       "      <td>-1.326966</td>\n",
       "      <td>1.433667</td>\n",
       "      <td>-0.037051</td>\n",
       "      <td>1.016276</td>\n",
       "      <td>-0.481035</td>\n",
       "      <td>1.061352</td>\n",
       "      <td>1.616178</td>\n",
       "      <td>1.540468</td>\n",
       "      <td>-0.958139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTO.XPR001_THP1_408H:CMAP-000:-666</th>\n",
       "      <td>-0.054865</td>\n",
       "      <td>-0.085794</td>\n",
       "      <td>-0.319447</td>\n",
       "      <td>0.180520</td>\n",
       "      <td>0.124284</td>\n",
       "      <td>-0.117936</td>\n",
       "      <td>-0.267994</td>\n",
       "      <td>0.429114</td>\n",
       "      <td>-0.144781</td>\n",
       "      <td>0.190815</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114969</td>\n",
       "      <td>0.308555</td>\n",
       "      <td>0.055869</td>\n",
       "      <td>-0.450732</td>\n",
       "      <td>-0.394338</td>\n",
       "      <td>0.029793</td>\n",
       "      <td>0.046924</td>\n",
       "      <td>-0.231632</td>\n",
       "      <td>-0.186150</td>\n",
       "      <td>-0.309360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOA001_A549_24H:N01</th>\n",
       "      <td>0.401776</td>\n",
       "      <td>1.197786</td>\n",
       "      <td>0.946556</td>\n",
       "      <td>0.794930</td>\n",
       "      <td>0.662958</td>\n",
       "      <td>0.473484</td>\n",
       "      <td>1.335021</td>\n",
       "      <td>0.338371</td>\n",
       "      <td>0.300303</td>\n",
       "      <td>0.690938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>0.171860</td>\n",
       "      <td>0.862337</td>\n",
       "      <td>0.525409</td>\n",
       "      <td>-0.029795</td>\n",
       "      <td>-0.263026</td>\n",
       "      <td>0.271724</td>\n",
       "      <td>0.934595</td>\n",
       "      <td>0.552001</td>\n",
       "      <td>-0.711617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_HT29_24H:CMAP-000:-666</th>\n",
       "      <td>0.038320</td>\n",
       "      <td>-0.426547</td>\n",
       "      <td>0.183131</td>\n",
       "      <td>0.450992</td>\n",
       "      <td>-0.414180</td>\n",
       "      <td>-0.619587</td>\n",
       "      <td>-0.318295</td>\n",
       "      <td>0.066966</td>\n",
       "      <td>-0.618409</td>\n",
       "      <td>0.539847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085557</td>\n",
       "      <td>0.018541</td>\n",
       "      <td>0.174058</td>\n",
       "      <td>-0.101450</td>\n",
       "      <td>-0.279539</td>\n",
       "      <td>-0.303862</td>\n",
       "      <td>0.019368</td>\n",
       "      <td>1.111968</td>\n",
       "      <td>0.387193</td>\n",
       "      <td>-0.770082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_HA1E_24H:CMAP-000:-666</th>\n",
       "      <td>0.319681</td>\n",
       "      <td>-0.182241</td>\n",
       "      <td>0.689418</td>\n",
       "      <td>0.542491</td>\n",
       "      <td>-0.124395</td>\n",
       "      <td>0.252069</td>\n",
       "      <td>-0.348502</td>\n",
       "      <td>0.145006</td>\n",
       "      <td>-0.018389</td>\n",
       "      <td>0.190280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048443</td>\n",
       "      <td>0.188158</td>\n",
       "      <td>0.422073</td>\n",
       "      <td>0.123565</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>-0.003442</td>\n",
       "      <td>0.924158</td>\n",
       "      <td>-0.212382</td>\n",
       "      <td>0.166562</td>\n",
       "      <td>0.142994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_A375_24H:CMAP-000:-666</th>\n",
       "      <td>0.091151</td>\n",
       "      <td>-0.007194</td>\n",
       "      <td>0.360459</td>\n",
       "      <td>0.430177</td>\n",
       "      <td>-0.443078</td>\n",
       "      <td>-0.370296</td>\n",
       "      <td>-0.450974</td>\n",
       "      <td>0.616529</td>\n",
       "      <td>0.258591</td>\n",
       "      <td>0.111886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571711</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.240619</td>\n",
       "      <td>-0.372428</td>\n",
       "      <td>-0.168089</td>\n",
       "      <td>-0.137313</td>\n",
       "      <td>0.157594</td>\n",
       "      <td>0.256362</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>-0.065995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_HEPG2_24H:CMAP-000:-666</th>\n",
       "      <td>-0.276361</td>\n",
       "      <td>-0.321295</td>\n",
       "      <td>0.412983</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>-0.144093</td>\n",
       "      <td>-0.374313</td>\n",
       "      <td>-0.488024</td>\n",
       "      <td>0.273988</td>\n",
       "      <td>-0.278131</td>\n",
       "      <td>-0.075510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440074</td>\n",
       "      <td>0.220422</td>\n",
       "      <td>-0.144075</td>\n",
       "      <td>-0.162023</td>\n",
       "      <td>-0.328652</td>\n",
       "      <td>-0.300582</td>\n",
       "      <td>0.469960</td>\n",
       "      <td>-0.533808</td>\n",
       "      <td>0.158130</td>\n",
       "      <td>-0.492051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_MCF7_24H:CMAP-000:-666</th>\n",
       "      <td>0.562066</td>\n",
       "      <td>0.520038</td>\n",
       "      <td>0.751154</td>\n",
       "      <td>0.046425</td>\n",
       "      <td>0.820798</td>\n",
       "      <td>0.413035</td>\n",
       "      <td>0.023128</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>-0.251062</td>\n",
       "      <td>0.249479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369176</td>\n",
       "      <td>-0.102268</td>\n",
       "      <td>0.466466</td>\n",
       "      <td>-0.158036</td>\n",
       "      <td>0.181730</td>\n",
       "      <td>-0.741085</td>\n",
       "      <td>0.759574</td>\n",
       "      <td>0.078421</td>\n",
       "      <td>-0.240611</td>\n",
       "      <td>0.000913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214 rows × 978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          16        23        25        30  \\\n",
       "OFL001_A549_96H:G15                 1.854175  1.868439 -0.140405 -0.278911   \n",
       "OFL001_MCF7_96H:J10                 0.081511  0.651525 -0.205014  0.054704   \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3  0.543459  1.647965 -1.731661  0.319534   \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666 -0.054865 -0.085794 -0.319447  0.180520   \n",
       "MOA001_A549_24H:N01                 0.401776  1.197786  0.946556  0.794930   \n",
       "...                                      ...       ...       ...       ...   \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666    0.038320 -0.426547  0.183131  0.450992   \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666    0.319681 -0.182241  0.689418  0.542491   \n",
       "DOSVAL001_A375_24H:CMAP-000:-666    0.091151 -0.007194  0.360459  0.430177   \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666  -0.276361 -0.321295  0.412983  0.040179   \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666    0.562066  0.520038  0.751154  0.046425   \n",
       "\n",
       "                                          39        47       102       128  \\\n",
       "OFL001_A549_96H:G15                 0.396597  0.334116  0.473704 -0.565553   \n",
       "OFL001_MCF7_96H:J10                 0.726742 -0.126017  0.200712  0.915557   \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3  1.078192  0.602553  0.323291  0.787790   \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666  0.124284 -0.117936 -0.267994  0.429114   \n",
       "MOA001_A549_24H:N01                 0.662958  0.473484  1.335021  0.338371   \n",
       "...                                      ...       ...       ...       ...   \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666   -0.414180 -0.619587 -0.318295  0.066966   \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666   -0.124395  0.252069 -0.348502  0.145006   \n",
       "DOSVAL001_A375_24H:CMAP-000:-666   -0.443078 -0.370296 -0.450974  0.616529   \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666  -0.144093 -0.374313 -0.488024  0.273988   \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666    0.820798  0.413035  0.023128  0.366703   \n",
       "\n",
       "                                         142       154  ...     94239  \\\n",
       "OFL001_A549_96H:G15                 1.372410  1.181299  ...  1.252141   \n",
       "OFL001_MCF7_96H:J10                 0.780285  0.007211  ...  0.341261   \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3  0.888264  1.532468  ...  0.704732   \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666 -0.144781  0.190815  ... -0.114969   \n",
       "MOA001_A549_24H:N01                 0.300303  0.690938  ...  0.020668   \n",
       "...                                      ...       ...  ...       ...   \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666   -0.618409  0.539847  ...  0.085557   \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666   -0.018389  0.190280  ... -0.048443   \n",
       "DOSVAL001_A375_24H:CMAP-000:-666    0.258591  0.111886  ... -0.571711   \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666  -0.278131 -0.075510  ... -0.440074   \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666   -0.251062  0.249479  ... -0.369176   \n",
       "\n",
       "                                      116832    124583    147179    148022  \\\n",
       "OFL001_A549_96H:G15                -0.291923  1.193942  0.978987  2.381282   \n",
       "OFL001_MCF7_96H:J10                 0.405606 -0.054713  0.264261 -0.096964   \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3 -1.326966  1.433667 -0.037051  1.016276   \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666  0.308555  0.055869 -0.450732 -0.394338   \n",
       "MOA001_A549_24H:N01                 0.171860  0.862337  0.525409 -0.029795   \n",
       "...                                      ...       ...       ...       ...   \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666    0.018541  0.174058 -0.101450 -0.279539   \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666    0.188158  0.422073  0.123565  0.097611   \n",
       "DOSVAL001_A375_24H:CMAP-000:-666    0.084373  0.240619 -0.372428 -0.168089   \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666   0.220422 -0.144075 -0.162023 -0.328652   \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666   -0.102268  0.466466 -0.158036  0.181730   \n",
       "\n",
       "                                      200081    200734    256364    375346  \\\n",
       "OFL001_A549_96H:G15                -1.065447  1.174847 -0.885704  0.879203   \n",
       "OFL001_MCF7_96H:J10                 0.752965 -0.249324 -1.176310  0.282062   \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3 -0.481035  1.061352  1.616178  1.540468   \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666  0.029793  0.046924 -0.231632 -0.186150   \n",
       "MOA001_A549_24H:N01                -0.263026  0.271724  0.934595  0.552001   \n",
       "...                                      ...       ...       ...       ...   \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666   -0.303862  0.019368  1.111968  0.387193   \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666   -0.003442  0.924158 -0.212382  0.166562   \n",
       "DOSVAL001_A375_24H:CMAP-000:-666   -0.137313  0.157594  0.256362  0.080780   \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666  -0.300582  0.469960 -0.533808  0.158130   \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666   -0.741085  0.759574  0.078421 -0.240611   \n",
       "\n",
       "                                      388650  \n",
       "OFL001_A549_96H:G15                 0.216700  \n",
       "OFL001_MCF7_96H:J10                -0.212717  \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3 -0.958139  \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666 -0.309360  \n",
       "MOA001_A549_24H:N01                -0.711617  \n",
       "...                                      ...  \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666   -0.770082  \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666    0.142994  \n",
       "DOSVAL001_A375_24H:CMAP-000:-666   -0.065995  \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666  -0.492051  \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666    0.000913  \n",
       "\n",
       "[3214 rows x 978 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gex data for controls\n",
    "cmap_controls = pd.read_csv('../preprocessing/preprocessed_data/baselineCell/cmap_all_baselines_q1.csv',index_col=0)\n",
    "display(cmap_controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5ecf9",
   "metadata": {},
   "source": [
    "# Train one trasnlation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01186e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'encoder_1_hiddens':[384,256],\n",
    "                'encoder_2_hiddens':[384,256],\n",
    "                'latent_dim': 128,\n",
    "                'decoder_1_hiddens':[256,384],\n",
    "                'decoder_2_hiddens':[256,384],\n",
    "                'dropout_decoder':0.2,\n",
    "                'dropout_encoder':0.1,\n",
    "                'encoder_activation':torch.nn.ELU(),\n",
    "                'decoder_activation':torch.nn.ELU(),\n",
    "                'V_dropout':0.25,\n",
    "                'state_class_hidden':[128,64,32],\n",
    "                'state_class_drop_in':0.5,\n",
    "                'state_class_drop':0.25,\n",
    "                'no_states':2,\n",
    "                'adv_class_hidden':[128,64,32],\n",
    "                'adv_class_drop_in':0.3,\n",
    "                'adv_class_drop':0.1,\n",
    "                'no_adv_class':2,\n",
    "                'encoding_lr':0.001,\n",
    "                'adv_lr':0.001,\n",
    "                'schedule_step_adv':200,\n",
    "                'gamma_adv':0.5,\n",
    "                'schedule_step_enc':200,\n",
    "                'gamma_enc':0.8,\n",
    "                'batch_size':512,\n",
    "                'epochs':1000,\n",
    "                'no_folds':5,\n",
    "                'v_reg':1e-04,\n",
    "                'state_class_reg':1e-02,\n",
    "                'enc_l2_reg':0.01,\n",
    "                'dec_l2_reg':0.01,\n",
    "                'lambda_mi_loss':100,\n",
    "                'effsize_reg': 100,\n",
    "                'cosine_loss': 10,\n",
    "                'adv_penalnty':100,\n",
    "                'reg_adv':1000,\n",
    "                'reg_classifier': 1000,\n",
    "                'similarity_reg' : 10,\n",
    "                'adversary_steps':4,\n",
    "                'autoencoder_wd': 0.,\n",
    "                'adversary_wd': 0.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92abbd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_betas = [1e-04,1e-03,1e-02,1e-01,1e0,1e1,1e2,1e3,1e4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a9327fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs =  model_params['batch_size']\n",
    "# k_folds=model_params['no_folds']\n",
    "NUM_EPOCHS=model_params['epochs']\n",
    "# kfold=KFold(n_splits=k_folds,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff272630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell = \"U2OS\"\n",
    "# df_result_all =  pd.read_csv('../results/PriorLossAnalysis/translation_results_testytest_'+cell+'.csv',index_col=0)\n",
    "# df_result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303b296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell-line : U2OS, prior beta 0.00, Split 1: Epoch=1/1000, pearson_1=0.1506, MSE_1=2.0080, pearson_2=0.1563, MSE_2=2.0707, MI Loss=0.6407, Prior Loss=0.0001, Cosine =0.5315, silimalityLoss =7.3215, loss=2154.2085\n"
     ]
    }
   ],
   "source": [
    "df_result_all = pd.DataFrame({})\n",
    "cell = \"U2OS\"\n",
    "j = 3\n",
    "for prior_beta in prior_betas:\n",
    "    genes_1 = np.load('../results/SameCellimputationModel/genes_subsets/genes_1'+cell+'_iter'+str(j)+'.npy',allow_pickle=True)\n",
    "    genes_2 = np.setdiff1d(cmap.columns.values,genes_1)\n",
    "    num_genes = genes_1.shape[0]\n",
    "    valPear = []\n",
    "    valPear_1 = []\n",
    "    valPear_2 = []\n",
    "    for i in range(model_params['no_folds']):\n",
    "        trainInfo = pd.read_csv('../preprocessing/preprocessed_data/SameCellimputationModel/'+cell+'/train_'+str(i)+'.csv',index_col=0)\n",
    "        valInfo = pd.read_csv('../preprocessing/preprocessed_data/SameCellimputationModel/'+cell+'/val_'+str(i)+'.csv',index_col=0)\n",
    "            \n",
    "        if len(trainInfo)<950:\n",
    "            bs = 256\n",
    "        else:\n",
    "            bs = model_params['batch_size']\n",
    "            \n",
    "        cmap_train = cmap.loc[trainInfo.sig_id,:]\n",
    "        cols = cmap_train.columns.values\n",
    "        cmap_train_shuffled = cmap_train.sample(frac=1, axis=1)\n",
    "        cmap_train_shuffled.columns = cols\n",
    "        cmap_val = cmap.loc[valInfo.sig_id,:]\n",
    "        N = len(cmap_train)\n",
    "        \n",
    "        curState_1 = torch.rand((N, model_params['latent_dim']), dtype=torch.float, requires_grad=False).to(device)\n",
    "        curState_2 = torch.rand((N, model_params['latent_dim']), dtype=torch.float, requires_grad=False).to(device)\n",
    "        # Network\n",
    "        decoder_1 = Decoder(model_params['latent_dim'],model_params['decoder_1_hiddens'],num_genes,\n",
    "                                dropRate=model_params['dropout_decoder'], \n",
    "                                activation=model_params['decoder_activation']).to(device)\n",
    "        decoder_2 = Decoder(model_params['latent_dim'],model_params['decoder_2_hiddens'],num_genes,\n",
    "                                dropRate=model_params['dropout_decoder'], \n",
    "                                activation=model_params['decoder_activation']).to(device)\n",
    "        encoder_1 = SimpleEncoder(num_genes,model_params['encoder_1_hiddens'],model_params['latent_dim'],\n",
    "                                      dropRate=model_params['dropout_encoder'], \n",
    "                                      activation=model_params['encoder_activation'],\n",
    "                                     normalizeOutput=False).to(device)\n",
    "        encoder_2 = SimpleEncoder(num_genes,model_params['encoder_2_hiddens'],model_params['latent_dim'],\n",
    "                                          dropRate=model_params['dropout_encoder'], \n",
    "                                          activation=model_params['encoder_activation'],\n",
    "                                     normalizeOutput=False).to(device)\n",
    "        prior_d = PriorDiscriminator(model_params['latent_dim']).to(device)\n",
    "        local_d = LocalDiscriminator(model_params['latent_dim'],model_params['latent_dim']).to(device)\n",
    "\n",
    "        allParams = list(decoder_1.parameters()) + list(encoder_1.parameters())\n",
    "        allParams = allParams + list(decoder_2.parameters()) + list(encoder_2.parameters())\n",
    "        allParams = allParams  + list(local_d.parameters())\n",
    "        allParams = allParams + list(prior_d.parameters())\n",
    "        optimizer = torch.optim.Adam(allParams, lr=model_params['encoding_lr'])\n",
    "        #optimizeD = torch.optim.Adam(prior_d.parameters(), lr=model_params['encoding_lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                        step_size=model_params['schedule_step_enc'],\n",
    "                                                        gamma=model_params['gamma_enc'])\n",
    "        trainLoss = []\n",
    "        trainLossSTD = []\n",
    "        for e in range(NUM_EPOCHS):\n",
    "            encoder_1.train()\n",
    "            decoder_1.train()\n",
    "            encoder_2.train()\n",
    "            decoder_2.train()\n",
    "            prior_d.train()\n",
    "            local_d.train()\n",
    "\n",
    "            trainloader = getSamples(N, bs)\n",
    "            trainLoss_ALL = []\n",
    "            for dataIndex in trainloader:\n",
    "\n",
    "                data_1 = torch.tensor(cmap_train.loc[:,genes_1].values).float()\n",
    "                data_1 = data_1[dataIndex,:].to(device)\n",
    "                data_2 = torch.tensor(cmap_train.loc[:,genes_2].values).float()\n",
    "                data_2 = data_2[dataIndex,:].to(device)\n",
    "                    \n",
    "                conditions = trainInfo.conditionId.values[dataIndex]\n",
    "                conditions = np.concatenate((conditions,conditions))\n",
    "                size = conditions.size\n",
    "                conditions = conditions.reshape(size,1)\n",
    "                conditions = conditions == conditions.transpose()\n",
    "                conditions = conditions*1\n",
    "                mask = torch.tensor(conditions).to(device).detach()\n",
    "                pos_mask = mask\n",
    "                neg_mask = 1 - mask\n",
    "                log_2 = math.log(2.)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                #optimizeD.zero_grad()\n",
    "                \n",
    "                z_1 = encoder_1(data_1)\n",
    "                z_2 = encoder_2(data_2)\n",
    "                    \n",
    "                #print('Epoch %s'%e)\n",
    "                #print(z_1)\n",
    "                    \n",
    "                latent_vectors = torch.cat((z_1, z_2), 0)\n",
    "                z_un = local_d(latent_vectors)\n",
    "                #z_un_1 = local_d(z_1)\n",
    "                #z_un_2 = local_d(z_2)\n",
    "                #res_un = torch.matmul(z_un_1, z_un_2.t())\n",
    "                res_un = torch.matmul(z_un, z_un.t())\n",
    "                    \n",
    "                #print(res_un)\n",
    "                    \n",
    "                Xhat_1 = decoder_1(z_1)\n",
    "                Xhat_2 = decoder_2(z_2)\n",
    "                loss_1 = torch.mean(torch.sum((Xhat_1 - data_1)**2,dim=1)) + encoder_1.L2Regularization(model_params['enc_l2_reg']) + decoder_1.L2Regularization(model_params['dec_l2_reg'])\n",
    "                loss_2 = torch.mean(torch.sum((Xhat_2 - data_2)**2,dim=1)) +encoder_2.L2Regularization(model_params['enc_l2_reg']) + decoder_2.L2Regularization(model_params['dec_l2_reg'])\n",
    "                    \n",
    "                silimalityLoss = torch.sum(torch.cdist(latent_vectors, latent_vectors) * pos_mask.float()) / pos_mask.float().sum()\n",
    "                #silimalityLoss = torch.mean(torch.cdist(z_1, z_2))\n",
    "                w1 = latent_vectors.norm(p=2, dim=1, keepdim=True)\n",
    "                w2 = latent_vectors.norm(p=2, dim=1, keepdim=True)\n",
    "                cosineLoss = torch.mm(latent_vectors, latent_vectors.t()) / (w1 * w2.t()).clamp(min=1e-6)\n",
    "                cosineLoss = torch.sum(cosineLoss * pos_mask.float()) / pos_mask.float().sum()\n",
    "                #cosineLoss = torch.mean(cosineLoss)\n",
    "\n",
    "                p_samples = res_un * pos_mask.float()\n",
    "                q_samples = res_un * neg_mask.float()\n",
    "\n",
    "                Ep = log_2 - F.softplus(- p_samples)\n",
    "                Eq = F.softplus(-q_samples) + q_samples - log_2\n",
    "\n",
    "                Ep = (Ep * pos_mask.float()).sum() / pos_mask.float().sum()\n",
    "                Eq = (Eq * neg_mask.float()).sum() / neg_mask.float().sum()\n",
    "                mi_loss = Eq - Ep\n",
    "                #mi_loss = torch.nan_to_num(mi_loss, nan=1e-03)\n",
    "\n",
    "                prior = torch.rand_like(torch.cat((z_1, z_2), 0))\n",
    "                #prior = torch.randn(torch.cat((z_1, z_2), 0).shape).to(device)\n",
    "                term_a = torch.log(prior_d(prior)).mean()\n",
    "                #term_b = torch.log(1.0 - prior_d(torch.cat((z_1, z_2), 0))).mean()\n",
    "                term_b = torch.log(prior_d(torch.cat((z_1, z_2), 0)) + 1e-06).mean()\n",
    "                prior_loss = -(term_a + term_b)* prior_beta\n",
    "                ### MSE-LIKE PRIOR\n",
    "                #prior_loss1 = prior_beta * uniformLoss(curState_1, dataIndex, z_1,maxConstraintFactor=1)\n",
    "                #prior_loss2 = prior_beta * uniformLoss(curState_2, dataIndex, z_2,maxConstraintFactor=1)\n",
    "                #prior_loss_binned = torch.mean(torch.sum((torch.cat((z_1, z_2), 0) - prior)**2,dim=1))\n",
    "                #prior_loss = 0.5*(prior_loss1+prior_loss2) + prior_loss_binned\n",
    "                ### KL-divergence prior\n",
    "                #mu1 = torch.mean(torch.cat((z_1, z_2), 0),0)\n",
    "                ##mu2 = torch.mean(prior,0)\n",
    "                #sd1 = torch.std(torch.cat((z_1, z_2), 0),0)\n",
    "                ##sd2 = torch.std(prior,0)\n",
    "                #prior_loss = prior_beta * kl_loss(mu1,sd1)\n",
    "                    \n",
    "                loss = loss_1 + loss_2 + model_params[\n",
    "                        'similarity_reg']*silimalityLoss - model_params[\n",
    "                        'cosine_loss'] * cosineLoss + prior_loss + model_params['lambda_mi_loss'] * mi_loss\n",
    "                loss.backward()\n",
    "                #prior_loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                #optimizeD.step()\n",
    "\n",
    "                pear_1 = pearson_r(Xhat_1.detach(), data_1.detach())\n",
    "                mse_1 = torch.mean(torch.mean((Xhat_1.detach() - data_1.detach()) ** 2, dim=1))\n",
    "                pear_2 = pearson_r(Xhat_2.detach(), data_2.detach())\n",
    "                mse_2 = torch.mean(torch.mean((Xhat_2.detach() - data_2.detach()) ** 2, dim=1))\n",
    "                trainLoss_ALL.append(loss.item())\n",
    "                    \n",
    "            if e%250==0:\n",
    "                outString = 'Cell-line : '+cell+', prior beta {:.2f}'.format(prior_beta)\n",
    "                outString += ', Split {:.0f}: Epoch={:.0f}/{:.0f}'.format(i + 1, e + 1, NUM_EPOCHS)\n",
    "                outString += ', pearson_1={:.4f}'.format(pear_1.item())\n",
    "                outString += ', MSE_1={:.4f}'.format(mse_1.item())\n",
    "                outString += ', pearson_2={:.4f}'.format(pear_2.item())\n",
    "                outString += ', MSE_2={:.4f}'.format(mse_2.item())\n",
    "                outString += ', MI Loss={:.4f}'.format(mi_loss.item())\n",
    "                outString += ', Prior Loss={:.4f}'.format(prior_loss.item())\n",
    "                #outString += ', Prior Loss 2={:.4f}'.format(prior_gen.item())\n",
    "                outString += ', Cosine ={:.4f}'.format(cosineLoss.item())\n",
    "                outString += ', silimalityLoss ={:.4f}'.format(silimalityLoss.item())\n",
    "                outString += ', loss={:.4f}'.format(loss.item())\n",
    "                print(outString)\n",
    "            scheduler.step()\n",
    "            trainLoss.append(np.mean(trainLoss_ALL))\n",
    "            trainLossSTD.append(np.std(trainLoss_ALL))\n",
    "        outString = 'Cell-line : '+cell+', prior beta {:.2f}'.format(prior_beta)\n",
    "        outString += ', Split {:.0f}: Epoch={:.0f}/{:.0f}'.format(i + 1, e + 1, NUM_EPOCHS)\n",
    "        outString += ', pearson_1={:.4f}'.format(pear_1.item())\n",
    "        outString += ', MSE_1={:.4f}'.format(mse_1.item())\n",
    "        outString += ', pearson_2={:.4f}'.format(pear_2.item())\n",
    "        outString += ', MSE_2={:.4f}'.format(mse_2.item())\n",
    "        outString += ', MI Loss={:.4f}'.format(mi_loss.item())\n",
    "        outString += ', Prior Loss={:.4f}'.format(prior_loss.item())\n",
    "        #outString += ', Prior Loss 2={:.4f}'.format(prior_gen.item())\n",
    "        outString += ', Cosine ={:.4f}'.format(cosineLoss.item())\n",
    "        outString += ', silimalityLoss ={:.4f}'.format(silimalityLoss.item())\n",
    "        outString += ', loss={:.4f}'.format(loss.item())\n",
    "        print(outString)\n",
    "        plt.figure()\n",
    "        plt.hist(torch.cat((z_1, z_2), 0).detach().flatten().cpu().numpy(),40)\n",
    "        plt.title('Prior beta %s fold %s'%(prior_beta,i))\n",
    "\n",
    "        encoder_1.eval()\n",
    "        decoder_1.eval()\n",
    "        encoder_2.eval()\n",
    "        decoder_2.eval()\n",
    "        prior_d.eval()\n",
    "        local_d.eval()\n",
    "            \n",
    "        print('Validation performance for cell %s for beta %s for split %s'%(cell,prior_beta,i+1))\n",
    "\n",
    "\n",
    "        X_1 = torch.tensor(cmap_val.loc[:,genes_1].values).float().to(device)\n",
    "        X_2 = torch.tensor(cmap_val.loc[:,genes_2].values).float().to(device)\n",
    "                    \n",
    "        z_1 = encoder_1(X_1)\n",
    "        z_2 = encoder_2(X_2)\n",
    "        Xhat_1 = decoder_1(z_1)\n",
    "        Xhat_2 = decoder_2(z_2)\n",
    "            \n",
    "        pear_1 = pearson_r(Xhat_1.detach(), X_1.detach())\n",
    "        pear_2 = pearson_r(Xhat_2.detach(), X_2.detach())\n",
    "        valPear_1.append(pear_1.item())\n",
    "        valPear_2.append(pear_2.item())\n",
    "\n",
    "        print('Pearson correlation 1: %s'%pear_1.item())\n",
    "        print('Pearson correlation 2: %s'%pear_2.item())\n",
    "    \n",
    "    \n",
    "        x_hat_2_equivalent = decoder_2(z_1).detach()\n",
    "        pearson_2 = pearson_r(x_hat_2_equivalent.detach(), X_2.detach())\n",
    "        print('Pearson correlation 1 to 2: %s'%pearson_2.item())\n",
    "        x_hat_1_equivalent = decoder_1(z_2).detach()\n",
    "        pearson_1 = pearson_r(x_hat_1_equivalent.detach(), X_1.detach())\n",
    "        print('Pearson correlation 2 to 1: %s'%pearson_1.item())\n",
    "        \n",
    "        valPear.append([pearson_2.item(),pearson_1.item()])\n",
    "            \n",
    "        torch.save(decoder_1,'../results/PriorLossAnalysis/models_AutoTransOp/'+cell+'_discr_uniform/decoder_1_fold%s_beta%s.pt'%(i,prior_beta))\n",
    "        torch.save(decoder_2,'../results/PriorLossAnalysis/models_AutoTransOp/'+cell+'_discr_uniform/decoder_2_fold%s_beta%s.pt'%(i,prior_beta))\n",
    "        torch.save(prior_d,'../results/PriorLossAnalysis/models_AutoTransOp/'+cell+'_discr_uniform/priorDiscr_fold%s_beta%s.pt'%(i,prior_beta))\n",
    "        torch.save(local_d,'../results/PriorLossAnalysis/models_AutoTransOp/'+cell+'_discr_uniform/localDiscr_fold%s_beta%s.pt'%(i,prior_beta))\n",
    "        torch.save(encoder_1,'../results/PriorLossAnalysis/models_AutoTransOp/'+cell+'_discr_uniform/encoder_1_fold%s_beta%s.pt'%(i,prior_beta))\n",
    "        torch.save(encoder_2,'../results/PriorLossAnalysis/models_AutoTransOp/'+cell+'_discr_uniform/encoder_2_fold%s_beta%s.pt'%(i,prior_beta))\n",
    "        \n",
    "    valPear = np.array(valPear)\n",
    "    df_result = pd.DataFrame({'model_pearson2to1':valPear[:,0],'model_pearson1to2':valPear[:,1],\n",
    "                              'recon_pear_2':valPear_2 ,'recon_pear_1':valPear_1})\n",
    "    df_result['model'] = 'model'\n",
    "    df_result['set'] = 'validation'\n",
    "    df_result['cell'] = cell\n",
    "    df_result['beta'] = prior_beta\n",
    "    df_result_all = df_result_all.append(df_result)\n",
    "    df_result_all.to_csv('../results/PriorLossAnalysis/translation_results_testytest_'+cell+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92730e08",
   "metadata": {},
   "source": [
    "# Embeed for uniform prior : uniformLoss, discriminator, KLD for beta =1 and 100, 10**4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba40872",
   "metadata": {},
   "source": [
    "### First uniformLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44994cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
