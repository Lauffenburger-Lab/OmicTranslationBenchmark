{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca4ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from evaluationUtils import r_square,get_cindex,pearson_r,pseudoAccuracy\n",
    "\n",
    "import json\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b491444",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb7340",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcaf010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "cmap = pd.read_csv('cmap_HT29_A375.csv',index_col = 0)\n",
    "#cmap_tf = pd.read_csv('../L1000_2021_11_23/cmap_compounds_tfs_repq1_tas03.tsv',\n",
    "#                       sep='\\t', low_memory=False, index_col=0)\n",
    "\n",
    "gene_size = len(cmap.columns)\n",
    "samples = cmap.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65d3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train generators\n",
    "def getSamples(N, batchSize):\n",
    "    order = np.random.permutation(N)\n",
    "    outList = []\n",
    "    while len(order)>0:\n",
    "        outList.append(order[0:batchSize])\n",
    "        order = order[batchSize:]\n",
    "    return outList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a58c2",
   "metadata": {},
   "source": [
    "# Define fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf2c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FITregressor(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, inputSize):\n",
    "        \n",
    "        super(FITregressor, self).__init__()\n",
    "        \n",
    "        alpha = torch.zeros(inputSize, requires_grad=True)\n",
    "        beta = torch.ones(inputSize, requires_grad=True)\n",
    "        self.alpha = torch.nn.Parameter(alpha)\n",
    "        self.beta = torch.nn.Parameter(beta)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.alpha + x*self.beta\n",
    "        return y\n",
    "    \n",
    "    def L1Regularization(self, L1=0.01):\n",
    "        alphaReg = L1 * torch.sum(torch.abs(self.alpha),)\n",
    "        betaReg = L1 * torch.sum(torch.abs(1-self.beta))\n",
    "        return alphaReg+betaReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c83d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitLoss(y_true,y_pred):\n",
    "    return torch.mean(torch.sum(torch.square(y_true-y_pred),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef082cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit = FITregressor(gene_size)\n",
    "# fit = fit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a22f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5000\n",
    "bs = 64\n",
    "#optimizer = torch.optim.Adam(fit.parameters(), lr=0.001, weight_decay=0)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.8)\n",
    "l1 = 0.1\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36eff492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: Epoch=5000/5000, r2=-1.7367, pearson=0.3453, MSE=0.8675, loss=8749.6379\n"
     ]
    }
   ],
   "source": [
    "# Train with no batch (too few data)\n",
    "\n",
    "trainPear = []\n",
    "trainSpear = []\n",
    "trainR2 =[]\n",
    "trainMSE = []\n",
    "trainAcc =[]\n",
    "\n",
    "valPear = []\n",
    "valSpear = []\n",
    "valR2 =[]\n",
    "valMSE = []\n",
    "valAcc = []\n",
    "\n",
    "for i in range(1):\n",
    "    # do staff about loading paired data\n",
    "    trainInfo_paired = pd.read_csv('10fold_validation_spit/train_paired_%s.csv'%i,index_col=0)\n",
    "    valInfo_paired = pd.read_csv('10fold_validation_spit/val_paired_%s.csv'%i,index_col=0)\n",
    "    N = len(trainInfo_paired)\n",
    "    \n",
    "    x1 = torch.tensor(cmap.loc[trainInfo_paired['sig_id.x'],:].values).to(device)\n",
    "    #sig_id.x to translate from A375 to HT29\n",
    "    x2 = torch.tensor(cmap.loc[trainInfo_paired['sig_id.y'],:].values).to(device)\n",
    "    \n",
    "    xval1 = torch.tensor(cmap.loc[valInfo_paired['sig_id.x'],:].values).to(device)\n",
    "    #sig_id.x to translate from A375 to HT29\n",
    "    xval2 = torch.tensor(cmap.loc[valInfo_paired['sig_id.y'],:].values).to(device)\n",
    "    \n",
    "    fit = FITregressor(gene_size)\n",
    "    fit = fit.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(fit.parameters(), lr=lr, weight_decay=0)\n",
    "    \n",
    "    for e in range(NUM_EPOCHS):\n",
    "        #trainloader = getSamples(N, bs)\n",
    "        fit.train()\n",
    "        #for dataIndex in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        #x=\n",
    "        y = fit(x1)\n",
    "        loss = fitLoss(x2,y) #+ fit.L1Regularization(L1=l1)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        pearson = pearson_r(y.detach(), x2.detach())\n",
    "        r2 = r_square(y.detach().flatten(), x2.detach().flatten())\n",
    "        mse = torch.mean(torch.mean((y.detach() - x2.detach())**2,dim=1))\n",
    "        \n",
    "        outString = 'Split {:.0f}: Epoch={:.0f}/{:.0f}'.format(i+1,e+1,NUM_EPOCHS)\n",
    "        outString += ', r2={:.4f}'.format(r2.item())\n",
    "        outString += ', pearson={:.4f}'.format(pearson.item())\n",
    "        outString += ', MSE={:.4f}'.format(mse.item())\n",
    "        outString += ', loss={:.4f}'.format(loss.item())\n",
    "        print(outString)\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    fit.eval()\n",
    "    \n",
    "    #x =\n",
    "    y = fit(x1)\n",
    "    \n",
    "    pearson = pearson_r(y.detach(), x2.detach())\n",
    "    r2 = r_square(y.detach().flatten(), x2.detach().flatten())\n",
    "    mse = torch.mean(torch.mean((y.detach() - x2.detach())**2,dim=1))\n",
    "    trainMSE.append(mse.item())\n",
    "    trainPear.append(pearson.item())\n",
    "    trainR2.append(r2.item())\n",
    "    #rhos =[]\n",
    "    #for jj in range(y.shape[0]):\n",
    "    #    rho,p = spearmanr(x2[jj,:].detach().cpu().numpy(),y[jj,:].detach().cpu().numpy())\n",
    "    #    rhos.append(rho)\n",
    "    #print('Validation spearman: %s'%np.mean(rhos))\n",
    "    #trainSpear.append(np.mean(rhos))\n",
    "    #trainAcc = pseudoAccuracy(x2.detach().cpu(),y.detach().cpu(),eps=1e-4)\n",
    "    \n",
    "    #xval = \n",
    "    yval = fit(xval1)\n",
    "    \n",
    "    pearson = pearson_r(yval.detach(), xval2.detach())\n",
    "    r2 = r_square(yval.detach().flatten(), xval2.detach().flatten())\n",
    "    mse = torch.mean(torch.mean((yval.detach() - xval2.detach())**2,dim=1))\n",
    "    \n",
    "    valMSE.append(mse.item())\n",
    "    valPear.append(pearson.item())\n",
    "    valR2.append(r2.item())\n",
    "    #rhos =[]\n",
    "    #for jj in range(yval.shape[0]):\n",
    "    #    rho,p = spearmanr(xval2[jj,:].detach().cpu().numpy(),yval[jj,:].detach().cpu().numpy())\n",
    "    #    rhos.append(rho)\n",
    "    #print('Validation spearman: %s'%np.mean(rhos))\n",
    "    #valSpear.append(np.mean(rhos))\n",
    "    #valAcc = pseudoAccuracy(xval2.detach().cpu(),yval.detach().cpu(),eps=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbbe2407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40480477275813476]\n",
      "[0.3453284472447295]\n"
     ]
    }
   ],
   "source": [
    "print(valPear)\n",
    "print(trainPear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(valPear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14717500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Validation mean accuracy: %s'%np.mean(valAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(trainPear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3cd851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Training mean accuracy: %s'%np.mean(trainAcc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
