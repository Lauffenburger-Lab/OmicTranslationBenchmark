{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a8b8132",
   "metadata": {},
   "source": [
    "# Before you begin make sure you have the appropriate folder structure and correct paths for you when saving results duting training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913b1b9d",
   "metadata": {},
   "source": [
    "# Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c35c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from scipy.stats import mannwhitneyu\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import umap\n",
    "\n",
    "from models import SimpleEncoder,Decoder,PriorDiscriminator,LocalDiscriminator,Classifier,SpeciesCovariate\n",
    "from evaluationUtils import r_square,get_cindex,pearson_r,pseudoAccuracy\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4d73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec26083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train generators\n",
    "def getSamples(N, batchSize):\n",
    "    order = np.random.permutation(N)\n",
    "    outList = []\n",
    "    while len(order)>0:\n",
    "        outList.append(order[0:batchSize])\n",
    "        order = order[batchSize:]\n",
    "    return outList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650bbeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(output, input):\n",
    "    grads = torch.autograd.grad(output, input, create_graph=True)\n",
    "    grads = grads[0].pow(2).mean()\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f97e64",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9ca653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>23</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>39</th>\n",
       "      <th>47</th>\n",
       "      <th>102</th>\n",
       "      <th>128</th>\n",
       "      <th>142</th>\n",
       "      <th>154</th>\n",
       "      <th>...</th>\n",
       "      <th>94239</th>\n",
       "      <th>116832</th>\n",
       "      <th>124583</th>\n",
       "      <th>147179</th>\n",
       "      <th>148022</th>\n",
       "      <th>200081</th>\n",
       "      <th>200734</th>\n",
       "      <th>256364</th>\n",
       "      <th>375346</th>\n",
       "      <th>388650</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCL001_HT29_24H:BRD-K42991516:10</th>\n",
       "      <td>0.266452</td>\n",
       "      <td>-0.250874</td>\n",
       "      <td>-0.854204</td>\n",
       "      <td>-0.041545</td>\n",
       "      <td>0.204450</td>\n",
       "      <td>0.709800</td>\n",
       "      <td>-0.328601</td>\n",
       "      <td>-0.498116</td>\n",
       "      <td>-1.454481</td>\n",
       "      <td>0.506321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536235</td>\n",
       "      <td>0.024452</td>\n",
       "      <td>0.928558</td>\n",
       "      <td>-0.453246</td>\n",
       "      <td>-0.140290</td>\n",
       "      <td>0.205065</td>\n",
       "      <td>1.148706</td>\n",
       "      <td>-1.933820</td>\n",
       "      <td>1.966937</td>\n",
       "      <td>-0.159919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCL001_HT29_24H:BRD-K50817946:10</th>\n",
       "      <td>6.074023</td>\n",
       "      <td>-0.524075</td>\n",
       "      <td>-0.635742</td>\n",
       "      <td>2.014629</td>\n",
       "      <td>-3.747274</td>\n",
       "      <td>2.109600</td>\n",
       "      <td>0.847576</td>\n",
       "      <td>-2.732549</td>\n",
       "      <td>-5.729352</td>\n",
       "      <td>2.164091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447939</td>\n",
       "      <td>1.543649</td>\n",
       "      <td>-3.775020</td>\n",
       "      <td>1.827991</td>\n",
       "      <td>-0.088051</td>\n",
       "      <td>0.382848</td>\n",
       "      <td>1.400255</td>\n",
       "      <td>-3.087269</td>\n",
       "      <td>1.392148</td>\n",
       "      <td>1.027263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOG002_A549_24H:BRD-K28296557-005-14-6:3.33</th>\n",
       "      <td>3.092555</td>\n",
       "      <td>1.760324</td>\n",
       "      <td>0.045857</td>\n",
       "      <td>-0.267738</td>\n",
       "      <td>-5.237659</td>\n",
       "      <td>-1.254134</td>\n",
       "      <td>-1.197927</td>\n",
       "      <td>-2.120804</td>\n",
       "      <td>-2.096229</td>\n",
       "      <td>0.799317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253642</td>\n",
       "      <td>-0.461737</td>\n",
       "      <td>-2.344703</td>\n",
       "      <td>1.581582</td>\n",
       "      <td>4.007076</td>\n",
       "      <td>-0.203330</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>1.502107</td>\n",
       "      <td>1.281574</td>\n",
       "      <td>0.450898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSBIO001_MCF7_24H:BRD-K77888550:9.5278</th>\n",
       "      <td>-1.680236</td>\n",
       "      <td>1.174203</td>\n",
       "      <td>0.295703</td>\n",
       "      <td>0.555778</td>\n",
       "      <td>0.136969</td>\n",
       "      <td>-1.507160</td>\n",
       "      <td>-0.068983</td>\n",
       "      <td>-0.468983</td>\n",
       "      <td>-1.894113</td>\n",
       "      <td>-0.035792</td>\n",
       "      <td>...</td>\n",
       "      <td>1.204646</td>\n",
       "      <td>-0.688365</td>\n",
       "      <td>-1.042315</td>\n",
       "      <td>2.571737</td>\n",
       "      <td>-0.085614</td>\n",
       "      <td>-3.472259</td>\n",
       "      <td>1.436653</td>\n",
       "      <td>-1.054814</td>\n",
       "      <td>1.873788</td>\n",
       "      <td>1.680525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSBIO001_NPC_24H:BRD-K09069264:10.2084</th>\n",
       "      <td>-1.401400</td>\n",
       "      <td>0.308703</td>\n",
       "      <td>1.178614</td>\n",
       "      <td>-2.114849</td>\n",
       "      <td>-0.020324</td>\n",
       "      <td>-0.393869</td>\n",
       "      <td>-2.599080</td>\n",
       "      <td>-0.983008</td>\n",
       "      <td>-0.063675</td>\n",
       "      <td>-0.549799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349096</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.356195</td>\n",
       "      <td>0.638253</td>\n",
       "      <td>0.862676</td>\n",
       "      <td>-0.106953</td>\n",
       "      <td>1.115011</td>\n",
       "      <td>2.205899</td>\n",
       "      <td>-0.306434</td>\n",
       "      <td>1.101611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_MCF7_24H:BRD-K30867024:10</th>\n",
       "      <td>-0.228277</td>\n",
       "      <td>-0.574911</td>\n",
       "      <td>0.545074</td>\n",
       "      <td>1.320753</td>\n",
       "      <td>-0.102422</td>\n",
       "      <td>1.058099</td>\n",
       "      <td>0.366014</td>\n",
       "      <td>-1.520461</td>\n",
       "      <td>-0.004073</td>\n",
       "      <td>-0.637326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057771</td>\n",
       "      <td>-0.660938</td>\n",
       "      <td>-1.952505</td>\n",
       "      <td>0.395937</td>\n",
       "      <td>1.790094</td>\n",
       "      <td>1.072335</td>\n",
       "      <td>1.657834</td>\n",
       "      <td>1.445156</td>\n",
       "      <td>2.031223</td>\n",
       "      <td>0.026611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL002_A375_24H:BRD-K10749593:20</th>\n",
       "      <td>4.415511</td>\n",
       "      <td>0.608378</td>\n",
       "      <td>1.604217</td>\n",
       "      <td>-0.911175</td>\n",
       "      <td>-2.611416</td>\n",
       "      <td>-1.742975</td>\n",
       "      <td>-2.500287</td>\n",
       "      <td>-2.503129</td>\n",
       "      <td>-3.472708</td>\n",
       "      <td>3.008501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916562</td>\n",
       "      <td>-1.403280</td>\n",
       "      <td>0.479218</td>\n",
       "      <td>4.528471</td>\n",
       "      <td>1.701896</td>\n",
       "      <td>0.141621</td>\n",
       "      <td>1.953133</td>\n",
       "      <td>-1.480089</td>\n",
       "      <td>1.549125</td>\n",
       "      <td>1.414482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL002_MCF7_24H:BRD-K14002526:20</th>\n",
       "      <td>1.311693</td>\n",
       "      <td>1.834785</td>\n",
       "      <td>1.277888</td>\n",
       "      <td>-0.224320</td>\n",
       "      <td>-0.365258</td>\n",
       "      <td>0.209443</td>\n",
       "      <td>0.166746</td>\n",
       "      <td>-2.112468</td>\n",
       "      <td>-0.870127</td>\n",
       "      <td>-0.083894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894919</td>\n",
       "      <td>-0.707055</td>\n",
       "      <td>0.519019</td>\n",
       "      <td>0.916627</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>0.126153</td>\n",
       "      <td>2.277303</td>\n",
       "      <td>-1.870382</td>\n",
       "      <td>1.021850</td>\n",
       "      <td>1.199542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_HT29_24H:BRD-K11624501:9.99164</th>\n",
       "      <td>1.540175</td>\n",
       "      <td>-0.196926</td>\n",
       "      <td>-0.094410</td>\n",
       "      <td>-1.951286</td>\n",
       "      <td>-2.848082</td>\n",
       "      <td>-2.478519</td>\n",
       "      <td>-1.257487</td>\n",
       "      <td>-1.247405</td>\n",
       "      <td>-4.006328</td>\n",
       "      <td>-0.362494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371798</td>\n",
       "      <td>3.735393</td>\n",
       "      <td>2.011243</td>\n",
       "      <td>1.693114</td>\n",
       "      <td>2.924200</td>\n",
       "      <td>2.535851</td>\n",
       "      <td>1.861230</td>\n",
       "      <td>-3.021530</td>\n",
       "      <td>0.127304</td>\n",
       "      <td>0.980487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_HCC515_24H:BRD-K48853221:10</th>\n",
       "      <td>3.427549</td>\n",
       "      <td>0.592761</td>\n",
       "      <td>-0.633423</td>\n",
       "      <td>-1.034512</td>\n",
       "      <td>1.337766</td>\n",
       "      <td>-0.138157</td>\n",
       "      <td>-1.700268</td>\n",
       "      <td>-0.425595</td>\n",
       "      <td>-1.978633</td>\n",
       "      <td>0.559278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.677538</td>\n",
       "      <td>-0.900451</td>\n",
       "      <td>0.067572</td>\n",
       "      <td>-0.153004</td>\n",
       "      <td>5.329951</td>\n",
       "      <td>-0.593923</td>\n",
       "      <td>0.100499</td>\n",
       "      <td>0.381238</td>\n",
       "      <td>0.816859</td>\n",
       "      <td>0.400983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13699 rows × 978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   16        23        25  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10             0.266452 -0.250874 -0.854204   \n",
       "PCL001_HT29_24H:BRD-K50817946:10             6.074023 -0.524075 -0.635742   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33  3.092555  1.760324  0.045857   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -1.680236  1.174203  0.295703   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084     -1.401400  0.308703  1.178614   \n",
       "...                                               ...       ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10         -0.228277 -0.574911  0.545074   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20          4.415511  0.608378  1.604217   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20          1.311693  1.834785  1.277888   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164     1.540175 -0.196926 -0.094410   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10        3.427549  0.592761 -0.633423   \n",
       "\n",
       "                                                   30        39        47  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10            -0.041545  0.204450  0.709800   \n",
       "PCL001_HT29_24H:BRD-K50817946:10             2.014629 -3.747274  2.109600   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33 -0.267738 -5.237659 -1.254134   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278      0.555778  0.136969 -1.507160   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084     -2.114849 -0.020324 -0.393869   \n",
       "...                                               ...       ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10          1.320753 -0.102422  1.058099   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20         -0.911175 -2.611416 -1.742975   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20         -0.224320 -0.365258  0.209443   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164    -1.951286 -2.848082 -2.478519   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10       -1.034512  1.337766 -0.138157   \n",
       "\n",
       "                                                  102       128       142  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10            -0.328601 -0.498116 -1.454481   \n",
       "PCL001_HT29_24H:BRD-K50817946:10             0.847576 -2.732549 -5.729352   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33 -1.197927 -2.120804 -2.096229   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -0.068983 -0.468983 -1.894113   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084     -2.599080 -0.983008 -0.063675   \n",
       "...                                               ...       ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10          0.366014 -1.520461 -0.004073   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20         -2.500287 -2.503129 -3.472708   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20          0.166746 -2.112468 -0.870127   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164    -1.257487 -1.247405 -4.006328   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10       -1.700268 -0.425595 -1.978633   \n",
       "\n",
       "                                                  154  ...     94239  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10             0.506321  ...  0.536235   \n",
       "PCL001_HT29_24H:BRD-K50817946:10             2.164091  ...  0.447939   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33  0.799317  ...  0.253642   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -0.035792  ...  1.204646   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084     -0.549799  ...  0.349096   \n",
       "...                                               ...  ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10         -0.637326  ... -0.057771   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20          3.008501  ...  0.916562   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20         -0.083894  ...  0.894919   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164    -0.362494  ... -0.371798   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10        0.559278  ... -0.677538   \n",
       "\n",
       "                                               116832    124583    147179  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10             0.024452  0.928558 -0.453246   \n",
       "PCL001_HT29_24H:BRD-K50817946:10             1.543649 -3.775020  1.827991   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33 -0.461737 -2.344703  1.581582   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -0.688365 -1.042315  2.571737   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084      0.017305  0.356195  0.638253   \n",
       "...                                               ...       ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10         -0.660938 -1.952505  0.395937   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20         -1.403280  0.479218  4.528471   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20         -0.707055  0.519019  0.916627   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164     3.735393  2.011243  1.693114   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10       -0.900451  0.067572 -0.153004   \n",
       "\n",
       "                                               148022    200081    200734  \\\n",
       "PCL001_HT29_24H:BRD-K42991516:10            -0.140290  0.205065  1.148706   \n",
       "PCL001_HT29_24H:BRD-K50817946:10            -0.088051  0.382848  1.400255   \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33  4.007076 -0.203330  0.715596   \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -0.085614 -3.472259  1.436653   \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084      0.862676 -0.106953  1.115011   \n",
       "...                                               ...       ...       ...   \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10          1.790094  1.072335  1.657834   \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20          1.701896  0.141621  1.953133   \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20          0.710227  0.126153  2.277303   \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164     2.924200  2.535851  1.861230   \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10        5.329951 -0.593923  0.100499   \n",
       "\n",
       "                                               256364    375346    388650  \n",
       "PCL001_HT29_24H:BRD-K42991516:10            -1.933820  1.966937 -0.159919  \n",
       "PCL001_HT29_24H:BRD-K50817946:10            -3.087269  1.392148  1.027263  \n",
       "HOG002_A549_24H:BRD-K28296557-005-14-6:3.33  1.502107  1.281574  0.450898  \n",
       "DOSBIO001_MCF7_24H:BRD-K77888550:9.5278     -1.054814  1.873788  1.680525  \n",
       "DOSBIO001_NPC_24H:BRD-K09069264:10.2084      2.205899 -0.306434  1.101611  \n",
       "...                                               ...       ...       ...  \n",
       "DOSVAL001_MCF7_24H:BRD-K30867024:10          1.445156  2.031223  0.026611  \n",
       "DOSVAL002_A375_24H:BRD-K10749593:20         -1.480089  1.549125  1.414482  \n",
       "DOSVAL002_MCF7_24H:BRD-K14002526:20         -1.870382  1.021850  1.199542  \n",
       "DOSVAL001_HT29_24H:BRD-K11624501:9.99164    -3.021530  0.127304  0.980487  \n",
       "DOSVAL001_HCC515_24H:BRD-K48853221:10        0.381238  0.816859  0.400983  \n",
       "\n",
       "[13699 rows x 978 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gex data \n",
    "cmap = pd.read_csv('../preprocessing/preprocessed_data/all_cmap_landmarks.csv',index_col=0)\n",
    "gene_size = len(cmap.columns)\n",
    "X = cmap.values\n",
    "display(cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65cc95ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>23</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>39</th>\n",
       "      <th>47</th>\n",
       "      <th>102</th>\n",
       "      <th>128</th>\n",
       "      <th>142</th>\n",
       "      <th>154</th>\n",
       "      <th>...</th>\n",
       "      <th>94239</th>\n",
       "      <th>116832</th>\n",
       "      <th>124583</th>\n",
       "      <th>147179</th>\n",
       "      <th>148022</th>\n",
       "      <th>200081</th>\n",
       "      <th>200734</th>\n",
       "      <th>256364</th>\n",
       "      <th>375346</th>\n",
       "      <th>388650</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OFL001_A549_96H:G15</th>\n",
       "      <td>1.854175</td>\n",
       "      <td>1.868439</td>\n",
       "      <td>-0.140405</td>\n",
       "      <td>-0.278911</td>\n",
       "      <td>0.396597</td>\n",
       "      <td>0.334116</td>\n",
       "      <td>0.473704</td>\n",
       "      <td>-0.565553</td>\n",
       "      <td>1.372410</td>\n",
       "      <td>1.181299</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252141</td>\n",
       "      <td>-0.291923</td>\n",
       "      <td>1.193942</td>\n",
       "      <td>0.978987</td>\n",
       "      <td>2.381282</td>\n",
       "      <td>-1.065447</td>\n",
       "      <td>1.174847</td>\n",
       "      <td>-0.885704</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.216700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFL001_MCF7_96H:J10</th>\n",
       "      <td>0.081511</td>\n",
       "      <td>0.651525</td>\n",
       "      <td>-0.205014</td>\n",
       "      <td>0.054704</td>\n",
       "      <td>0.726742</td>\n",
       "      <td>-0.126017</td>\n",
       "      <td>0.200712</td>\n",
       "      <td>0.915557</td>\n",
       "      <td>0.780285</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341261</td>\n",
       "      <td>0.405606</td>\n",
       "      <td>-0.054713</td>\n",
       "      <td>0.264261</td>\n",
       "      <td>-0.096964</td>\n",
       "      <td>0.752965</td>\n",
       "      <td>-0.249324</td>\n",
       "      <td>-1.176310</td>\n",
       "      <td>0.282062</td>\n",
       "      <td>-0.212717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABY001_NCIH1975_XH:CMAP-000:-666:3</th>\n",
       "      <td>0.543459</td>\n",
       "      <td>1.647965</td>\n",
       "      <td>-1.731661</td>\n",
       "      <td>0.319534</td>\n",
       "      <td>1.078192</td>\n",
       "      <td>0.602553</td>\n",
       "      <td>0.323291</td>\n",
       "      <td>0.787790</td>\n",
       "      <td>0.888264</td>\n",
       "      <td>1.532468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704732</td>\n",
       "      <td>-1.326966</td>\n",
       "      <td>1.433667</td>\n",
       "      <td>-0.037051</td>\n",
       "      <td>1.016276</td>\n",
       "      <td>-0.481035</td>\n",
       "      <td>1.061352</td>\n",
       "      <td>1.616178</td>\n",
       "      <td>1.540468</td>\n",
       "      <td>-0.958139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTO.XPR001_THP1_408H:CMAP-000:-666</th>\n",
       "      <td>-0.054865</td>\n",
       "      <td>-0.085794</td>\n",
       "      <td>-0.319447</td>\n",
       "      <td>0.180520</td>\n",
       "      <td>0.124284</td>\n",
       "      <td>-0.117936</td>\n",
       "      <td>-0.267994</td>\n",
       "      <td>0.429114</td>\n",
       "      <td>-0.144781</td>\n",
       "      <td>0.190815</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114969</td>\n",
       "      <td>0.308555</td>\n",
       "      <td>0.055869</td>\n",
       "      <td>-0.450732</td>\n",
       "      <td>-0.394338</td>\n",
       "      <td>0.029793</td>\n",
       "      <td>0.046924</td>\n",
       "      <td>-0.231632</td>\n",
       "      <td>-0.186150</td>\n",
       "      <td>-0.309360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOA001_A549_24H:N01</th>\n",
       "      <td>0.401776</td>\n",
       "      <td>1.197786</td>\n",
       "      <td>0.946556</td>\n",
       "      <td>0.794930</td>\n",
       "      <td>0.662958</td>\n",
       "      <td>0.473484</td>\n",
       "      <td>1.335021</td>\n",
       "      <td>0.338371</td>\n",
       "      <td>0.300303</td>\n",
       "      <td>0.690938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>0.171860</td>\n",
       "      <td>0.862337</td>\n",
       "      <td>0.525409</td>\n",
       "      <td>-0.029795</td>\n",
       "      <td>-0.263026</td>\n",
       "      <td>0.271724</td>\n",
       "      <td>0.934595</td>\n",
       "      <td>0.552001</td>\n",
       "      <td>-0.711617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_HT29_24H:CMAP-000:-666</th>\n",
       "      <td>0.038320</td>\n",
       "      <td>-0.426547</td>\n",
       "      <td>0.183131</td>\n",
       "      <td>0.450992</td>\n",
       "      <td>-0.414180</td>\n",
       "      <td>-0.619587</td>\n",
       "      <td>-0.318295</td>\n",
       "      <td>0.066966</td>\n",
       "      <td>-0.618409</td>\n",
       "      <td>0.539847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085557</td>\n",
       "      <td>0.018541</td>\n",
       "      <td>0.174058</td>\n",
       "      <td>-0.101450</td>\n",
       "      <td>-0.279539</td>\n",
       "      <td>-0.303862</td>\n",
       "      <td>0.019368</td>\n",
       "      <td>1.111968</td>\n",
       "      <td>0.387193</td>\n",
       "      <td>-0.770082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_HA1E_24H:CMAP-000:-666</th>\n",
       "      <td>0.319681</td>\n",
       "      <td>-0.182241</td>\n",
       "      <td>0.689418</td>\n",
       "      <td>0.542491</td>\n",
       "      <td>-0.124395</td>\n",
       "      <td>0.252069</td>\n",
       "      <td>-0.348502</td>\n",
       "      <td>0.145006</td>\n",
       "      <td>-0.018389</td>\n",
       "      <td>0.190280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048443</td>\n",
       "      <td>0.188158</td>\n",
       "      <td>0.422073</td>\n",
       "      <td>0.123565</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>-0.003442</td>\n",
       "      <td>0.924158</td>\n",
       "      <td>-0.212382</td>\n",
       "      <td>0.166562</td>\n",
       "      <td>0.142994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_A375_24H:CMAP-000:-666</th>\n",
       "      <td>0.091151</td>\n",
       "      <td>-0.007194</td>\n",
       "      <td>0.360459</td>\n",
       "      <td>0.430177</td>\n",
       "      <td>-0.443078</td>\n",
       "      <td>-0.370296</td>\n",
       "      <td>-0.450974</td>\n",
       "      <td>0.616529</td>\n",
       "      <td>0.258591</td>\n",
       "      <td>0.111886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571711</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.240619</td>\n",
       "      <td>-0.372428</td>\n",
       "      <td>-0.168089</td>\n",
       "      <td>-0.137313</td>\n",
       "      <td>0.157594</td>\n",
       "      <td>0.256362</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>-0.065995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_HEPG2_24H:CMAP-000:-666</th>\n",
       "      <td>-0.276361</td>\n",
       "      <td>-0.321295</td>\n",
       "      <td>0.412983</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>-0.144093</td>\n",
       "      <td>-0.374313</td>\n",
       "      <td>-0.488024</td>\n",
       "      <td>0.273988</td>\n",
       "      <td>-0.278131</td>\n",
       "      <td>-0.075510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440074</td>\n",
       "      <td>0.220422</td>\n",
       "      <td>-0.144075</td>\n",
       "      <td>-0.162023</td>\n",
       "      <td>-0.328652</td>\n",
       "      <td>-0.300582</td>\n",
       "      <td>0.469960</td>\n",
       "      <td>-0.533808</td>\n",
       "      <td>0.158130</td>\n",
       "      <td>-0.492051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOSVAL001_MCF7_24H:CMAP-000:-666</th>\n",
       "      <td>0.562066</td>\n",
       "      <td>0.520038</td>\n",
       "      <td>0.751154</td>\n",
       "      <td>0.046425</td>\n",
       "      <td>0.820798</td>\n",
       "      <td>0.413035</td>\n",
       "      <td>0.023128</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>-0.251062</td>\n",
       "      <td>0.249479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369176</td>\n",
       "      <td>-0.102268</td>\n",
       "      <td>0.466466</td>\n",
       "      <td>-0.158036</td>\n",
       "      <td>0.181730</td>\n",
       "      <td>-0.741085</td>\n",
       "      <td>0.759574</td>\n",
       "      <td>0.078421</td>\n",
       "      <td>-0.240611</td>\n",
       "      <td>0.000913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214 rows × 978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          16        23        25        30  \\\n",
       "OFL001_A549_96H:G15                 1.854175  1.868439 -0.140405 -0.278911   \n",
       "OFL001_MCF7_96H:J10                 0.081511  0.651525 -0.205014  0.054704   \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3  0.543459  1.647965 -1.731661  0.319534   \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666 -0.054865 -0.085794 -0.319447  0.180520   \n",
       "MOA001_A549_24H:N01                 0.401776  1.197786  0.946556  0.794930   \n",
       "...                                      ...       ...       ...       ...   \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666    0.038320 -0.426547  0.183131  0.450992   \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666    0.319681 -0.182241  0.689418  0.542491   \n",
       "DOSVAL001_A375_24H:CMAP-000:-666    0.091151 -0.007194  0.360459  0.430177   \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666  -0.276361 -0.321295  0.412983  0.040179   \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666    0.562066  0.520038  0.751154  0.046425   \n",
       "\n",
       "                                          39        47       102       128  \\\n",
       "OFL001_A549_96H:G15                 0.396597  0.334116  0.473704 -0.565553   \n",
       "OFL001_MCF7_96H:J10                 0.726742 -0.126017  0.200712  0.915557   \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3  1.078192  0.602553  0.323291  0.787790   \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666  0.124284 -0.117936 -0.267994  0.429114   \n",
       "MOA001_A549_24H:N01                 0.662958  0.473484  1.335021  0.338371   \n",
       "...                                      ...       ...       ...       ...   \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666   -0.414180 -0.619587 -0.318295  0.066966   \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666   -0.124395  0.252069 -0.348502  0.145006   \n",
       "DOSVAL001_A375_24H:CMAP-000:-666   -0.443078 -0.370296 -0.450974  0.616529   \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666  -0.144093 -0.374313 -0.488024  0.273988   \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666    0.820798  0.413035  0.023128  0.366703   \n",
       "\n",
       "                                         142       154  ...     94239  \\\n",
       "OFL001_A549_96H:G15                 1.372410  1.181299  ...  1.252141   \n",
       "OFL001_MCF7_96H:J10                 0.780285  0.007211  ...  0.341261   \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3  0.888264  1.532468  ...  0.704732   \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666 -0.144781  0.190815  ... -0.114969   \n",
       "MOA001_A549_24H:N01                 0.300303  0.690938  ...  0.020668   \n",
       "...                                      ...       ...  ...       ...   \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666   -0.618409  0.539847  ...  0.085557   \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666   -0.018389  0.190280  ... -0.048443   \n",
       "DOSVAL001_A375_24H:CMAP-000:-666    0.258591  0.111886  ... -0.571711   \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666  -0.278131 -0.075510  ... -0.440074   \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666   -0.251062  0.249479  ... -0.369176   \n",
       "\n",
       "                                      116832    124583    147179    148022  \\\n",
       "OFL001_A549_96H:G15                -0.291923  1.193942  0.978987  2.381282   \n",
       "OFL001_MCF7_96H:J10                 0.405606 -0.054713  0.264261 -0.096964   \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3 -1.326966  1.433667 -0.037051  1.016276   \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666  0.308555  0.055869 -0.450732 -0.394338   \n",
       "MOA001_A549_24H:N01                 0.171860  0.862337  0.525409 -0.029795   \n",
       "...                                      ...       ...       ...       ...   \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666    0.018541  0.174058 -0.101450 -0.279539   \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666    0.188158  0.422073  0.123565  0.097611   \n",
       "DOSVAL001_A375_24H:CMAP-000:-666    0.084373  0.240619 -0.372428 -0.168089   \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666   0.220422 -0.144075 -0.162023 -0.328652   \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666   -0.102268  0.466466 -0.158036  0.181730   \n",
       "\n",
       "                                      200081    200734    256364    375346  \\\n",
       "OFL001_A549_96H:G15                -1.065447  1.174847 -0.885704  0.879203   \n",
       "OFL001_MCF7_96H:J10                 0.752965 -0.249324 -1.176310  0.282062   \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3 -0.481035  1.061352  1.616178  1.540468   \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666  0.029793  0.046924 -0.231632 -0.186150   \n",
       "MOA001_A549_24H:N01                -0.263026  0.271724  0.934595  0.552001   \n",
       "...                                      ...       ...       ...       ...   \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666   -0.303862  0.019368  1.111968  0.387193   \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666   -0.003442  0.924158 -0.212382  0.166562   \n",
       "DOSVAL001_A375_24H:CMAP-000:-666   -0.137313  0.157594  0.256362  0.080780   \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666  -0.300582  0.469960 -0.533808  0.158130   \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666   -0.741085  0.759574  0.078421 -0.240611   \n",
       "\n",
       "                                      388650  \n",
       "OFL001_A549_96H:G15                 0.216700  \n",
       "OFL001_MCF7_96H:J10                -0.212717  \n",
       "ABY001_NCIH1975_XH:CMAP-000:-666:3 -0.958139  \n",
       "ZTO.XPR001_THP1_408H:CMAP-000:-666 -0.309360  \n",
       "MOA001_A549_24H:N01                -0.711617  \n",
       "...                                      ...  \n",
       "DOSVAL001_HT29_24H:CMAP-000:-666   -0.770082  \n",
       "DOSVAL001_HA1E_24H:CMAP-000:-666    0.142994  \n",
       "DOSVAL001_A375_24H:CMAP-000:-666   -0.065995  \n",
       "DOSVAL001_HEPG2_24H:CMAP-000:-666  -0.492051  \n",
       "DOSVAL001_MCF7_24H:CMAP-000:-666    0.000913  \n",
       "\n",
       "[3214 rows x 978 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gex data for controls\n",
    "cmap_controls = pd.read_csv('../preprocessing/preprocessed_data/baselineCell/cmap_all_baselines_q1.csv',index_col=0)\n",
    "display(cmap_controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5ecf9",
   "metadata": {},
   "source": [
    "# Train CPA model but without pre-training adverse\n",
    "Just for a few initial epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5480b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'encoder_1_hiddens':[384,256],\n",
    "                'encoder_2_hiddens':[384,256],\n",
    "                'latent_dim': 128,\n",
    "                'decoder_1_hiddens':[256,384],\n",
    "                'decoder_2_hiddens':[256,384],\n",
    "                'dropout_decoder':0.2,\n",
    "                'dropout_encoder':0.1,\n",
    "                'encoder_activation':torch.nn.ELU(),\n",
    "                'decoder_activation':torch.nn.ELU(),\n",
    "                'V_dropout':0.25,\n",
    "                'state_class_hidden':[64,32,16],#[128,64,32],\n",
    "                'state_class_drop_in':0.5,\n",
    "                'state_class_drop':0.25,\n",
    "                'no_states':2,\n",
    "                'adv_class_hidden':[128,64,32],\n",
    "                'adv_class_drop_in':0.3,\n",
    "                'adv_class_drop':0.1,\n",
    "                'no_adv_class':2,\n",
    "                'encoding_lr':0.001,\n",
    "                'adv_lr':0.001,\n",
    "                'schedule_step_adv':200,\n",
    "                'gamma_adv':0.5,\n",
    "                'schedule_step_enc':200,\n",
    "                'gamma_enc':0.8,\n",
    "                'batch_size':512,\n",
    "                'epochs':1000,\n",
    "                'prior_beta':1.0,\n",
    "                'no_folds':5,\n",
    "                'v_reg':1e-04,\n",
    "                'state_class_reg':1e-02,\n",
    "                'enc_l2_reg':0.01,\n",
    "                'dec_l2_reg':0.01,\n",
    "                'lambda_mi_loss':100,\n",
    "                'effsize_reg': 100,\n",
    "                'cosine_loss': 40,\n",
    "                'adv_penalnty':100,\n",
    "                'reg_adv':1000,\n",
    "                'reg_classifier': 100,\n",
    "                'similarity_reg' : 10,\n",
    "                'adversary_steps':4,\n",
    "                'autoencoder_wd': 0.,\n",
    "                'adversary_wd': 0.}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a9327fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs =  model_params['batch_size']\n",
    "NUM_EPOCHS=model_params['epochs']\n",
    "class_criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "318fc9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genes = int(0.5*gene_size)\n",
    "random_iterations = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d753a5",
   "metadata": {},
   "source": [
    "### Uncomment the last line of the cell to save df_result_all at every iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_all = pd.DataFrame({})\n",
    "for cell in [\"PC3\",\"HT29\",\"MCF7\",\"A549\",\"NPC\",\"HEPG2\",\"A375\",\"YAPC\",\"U2OS\",\"MCF10A\",\"HA1E\",\"HCC515\",\"ASC\",\"VCAP\",\"HUVEC\",\"HELA\"]:\n",
    "    for j in range(random_iterations):\n",
    "        #genes_1 = np.random.choice(cmap.columns.values, size=num_genes, replace=False)\n",
    "        genes_1 = np.load('../results/SameCellimputationModel/genes_subsets/genes_1'+cell+'_iter'+str(j)+'.npy',allow_pickle=True)\n",
    "        genes_2 = np.setdiff1d(cmap.columns.values,genes_1)\n",
    "        valPear = []\n",
    "        valPear_1 = []\n",
    "        valPear_2 = []\n",
    "        valPear_controls = []\n",
    "        valPear_controls_1 = []\n",
    "        valPear_controls_2 = []\n",
    "        \n",
    "        valPear_shuffled = []\n",
    "        valPear_1_shuffled = []\n",
    "        valPear_2_shuffled = []\n",
    "        valPear_controls_shuffled = []\n",
    "        valPear_controls_1_shuffled = []\n",
    "        valPear_controls_2_shuffled = []\n",
    "        \n",
    "        valF1 = []\n",
    "        valClassAcc = []\n",
    "            \n",
    "        for i in range(model_params['no_folds']):\n",
    "            trainInfo = pd.read_csv('../preprocessing/preprocessed_data/SameCellimputationModel/'+cell+'/train_'+str(i)+'.csv',index_col=0)\n",
    "            valInfo = pd.read_csv('../preprocessing/preprocessed_data/SameCellimputationModel/'+cell+'/val_'+str(i)+'.csv',index_col=0)\n",
    "            \n",
    "            if len(trainInfo)<950:\n",
    "                bs = 256\n",
    "            else:\n",
    "                bs = model_params['batch_size']\n",
    "            \n",
    "            cmap_train = cmap.loc[trainInfo.sig_id,:]\n",
    "            cols = cmap_train.columns.values\n",
    "            cmap_train_shuffled = cmap_train.sample(frac=1, axis=1)\n",
    "            cmap_train_shuffled.columns = cols\n",
    "            cmap_val = cmap.loc[valInfo.sig_id,:]\n",
    "            N = len(cmap_train)\n",
    "\n",
    "            # Network\n",
    "            decoder_1 = Decoder(model_params['latent_dim'],model_params['decoder_1_hiddens'],num_genes,\n",
    "                                dropRate=model_params['dropout_decoder'], \n",
    "                                activation=model_params['decoder_activation']).to(device)\n",
    "            decoder_2 = Decoder(model_params['latent_dim'],model_params['decoder_2_hiddens'],num_genes,\n",
    "                                dropRate=model_params['dropout_decoder'], \n",
    "                                activation=model_params['decoder_activation']).to(device)\n",
    "            encoder_1 = SimpleEncoder(num_genes,model_params['encoder_1_hiddens'],model_params['latent_dim'],\n",
    "                                      dropRate=model_params['dropout_encoder'], \n",
    "                                      activation=model_params['encoder_activation'],\n",
    "                                     normalizeOutput=False).to(device)\n",
    "            encoder_2 = SimpleEncoder(num_genes,model_params['encoder_2_hiddens'],model_params['latent_dim'],\n",
    "                                          dropRate=model_params['dropout_encoder'], \n",
    "                                          activation=model_params['encoder_activation'],\n",
    "                                     normalizeOutput=False).to(device)\n",
    "            prior_d = PriorDiscriminator(model_params['latent_dim']).to(device)\n",
    "            local_d = LocalDiscriminator(model_params['latent_dim'],model_params['latent_dim']).to(device)\n",
    "            classifier = Classifier(in_channel=model_params['latent_dim'],\n",
    "                                    hidden_layers=model_params['state_class_hidden'],\n",
    "                                    num_classes=model_params['no_states'],\n",
    "                                    drop_in=model_params['state_class_drop_in'],\n",
    "                                    drop=model_params['state_class_drop']).to(device)\n",
    "            adverse_classifier = Classifier(in_channel=model_params['latent_dim'],\n",
    "                                            hidden_layers=model_params['adv_class_hidden'],\n",
    "                                            num_classes=model_params['no_adv_class'],\n",
    "                                            drop_in=model_params['adv_class_drop_in'],\n",
    "                                            drop=model_params['adv_class_drop']).to(device)\n",
    "            Vsp = SpeciesCovariate(2,model_params['latent_dim'],dropRate=model_params['V_dropout']).to(device)\n",
    "            \n",
    "            #encoder_interm_1 = SimpleEncoder(model_params['latent_dim'],\n",
    "            #                                [int(model_params['latent_dim']/2)],\n",
    "            #                                int(model_params['latent_dim']/2),\n",
    "            #                                dropRate=0.01,\n",
    "            #                                activation=model_params['encoder_activation'],\n",
    "            #                                normalizeOutput=True).to(device)\n",
    "            #encoder_interm_2 = SimpleEncoder(model_params['latent_dim'],\n",
    "            #                                [int(model_params['latent_dim']/2)],\n",
    "            #                                int(model_params['latent_dim']/2),\n",
    "            #                                dropRate=0.01,\n",
    "            #                                activation=model_params['encoder_activation'],\n",
    "            #                                normalizeOutput=True).to(device)\n",
    "\n",
    "            allParams = list(decoder_1.parameters()) + list(encoder_1.parameters())\n",
    "            allParams = allParams + list(decoder_2.parameters()) + list(encoder_2.parameters())\n",
    "            allParams = allParams  + list(local_d.parameters())\n",
    "            allParams = allParams + list(prior_d.parameters())\n",
    "            allParams = allParams + list(Vsp.parameters())\n",
    "            #allParams = allParams + list(encoder_interm_1.parameters()) + list(encoder_interm_2.parameters())\n",
    "            allParams = allParams + list(classifier.parameters())\n",
    "            optimizer_adv = torch.optim.Adam(adverse_classifier.parameters(),\n",
    "                                             lr= model_params['adv_lr'], \n",
    "                                             weight_decay=model_params['adversary_wd'])\n",
    "            optimizer = torch.optim.Adam(allParams,\n",
    "                                         lr=model_params['encoding_lr'],\n",
    "                                         weight_decay=model_params['autoencoder_wd'])\n",
    "            if model_params['schedule_step_adv'] is not None:\n",
    "                scheduler_adv = torch.optim.lr_scheduler.StepLR(optimizer_adv,\n",
    "                                                                step_size=model_params['schedule_step_adv'],\n",
    "                                                                gamma=model_params['gamma_adv'])\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                        step_size=model_params['schedule_step_enc'],\n",
    "                                                        gamma=model_params['gamma_enc'])\n",
    "            #trainLoss = []\n",
    "            #trainLossSTD = []\n",
    "            for e in range(NUM_EPOCHS):\n",
    "                encoder_1.train()\n",
    "                decoder_1.train()\n",
    "                encoder_2.train()\n",
    "                decoder_2.train()\n",
    "                prior_d.train()\n",
    "                local_d.train()\n",
    "                classifier.train()\n",
    "                adverse_classifier.train()\n",
    "                Vsp.train()\n",
    "                #encoder_interm_1.train()\n",
    "                #encoder_interm_2.train()\n",
    "\n",
    "                trainloader = getSamples(N, bs)\n",
    "                trainLoss_ALL = []\n",
    "                for dataIndex in trainloader:\n",
    "\n",
    "                    data_1 = torch.tensor(cmap_train.loc[:,genes_1].values).float()\n",
    "                    data_1 = data_1[dataIndex,:].to(device)\n",
    "                    data_2 = torch.tensor(cmap_train.loc[:,genes_2].values).float()\n",
    "                    data_2 = data_2[dataIndex,:].to(device)\n",
    "                    \n",
    "                    z_species_1 = torch.cat((torch.ones(data_1.shape[0],1),\n",
    "                                     torch.zeros(data_1.shape[0],1)),1).to(device)\n",
    "                    z_species_2 = torch.cat((torch.zeros(data_2.shape[0],1),\n",
    "                                     torch.ones(data_2.shape[0],1)),1).to(device)\n",
    "                    \n",
    "                    conditions = trainInfo.conditionId.values[dataIndex]\n",
    "                    conditions = np.concatenate((conditions,conditions))\n",
    "                    size = conditions.size\n",
    "                    conditions = conditions.reshape(size,1)\n",
    "                    conditions = conditions == conditions.transpose()\n",
    "                    conditions = conditions*1\n",
    "                    mask = torch.tensor(conditions).to(device).detach()\n",
    "                    pos_mask = mask\n",
    "                    neg_mask = 1 - mask\n",
    "                    log_2 = math.log(2.)\n",
    "                    optimizer_adv.zero_grad()\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    z_base_1 = encoder_1(data_1)\n",
    "                    z_base_2 = encoder_2(data_2)\n",
    "                    latent_base_vectors = torch.cat((z_base_1, z_base_2), 0)\n",
    "                    labels_adv = adverse_classifier(latent_base_vectors)\n",
    "                    true_labels = torch.cat((torch.ones(z_base_1.shape[0]),\n",
    "                        torch.zeros(z_base_2.shape[0])),0).long().to(device)\n",
    "                    _, predicted = torch.max(labels_adv, 1)\n",
    "                    predicted = predicted.cpu().numpy()\n",
    "                    cf_matrix = confusion_matrix(true_labels.cpu().numpy(),predicted)\n",
    "                    tn, fp, fn, tp = cf_matrix.ravel()\n",
    "                    f1_basal_trained = 2*tp/(2*tp+fp+fn)\n",
    "                    adv_entropy = class_criterion(labels_adv,true_labels)\n",
    "                    adversary_drugs_penalty = compute_gradients(labels_adv.sum(), latent_base_vectors)\n",
    "                    loss_adv = adv_entropy + model_params['adv_penalnty'] * adversary_drugs_penalty\n",
    "                    loss_adv.backward()\n",
    "                    optimizer_adv.step()\n",
    "                    \n",
    "                    if e>25:\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        z_base_1 = encoder_1(data_1)\n",
    "                        z_base_2 = encoder_2(data_2)\n",
    "                        latent_base_vectors = torch.cat((z_base_1, z_base_2), 0)\n",
    "                        \n",
    "                        z_un = local_d(latent_base_vectors)\n",
    "                        res_un = torch.matmul(z_un, z_un.t())\n",
    "                        \n",
    "                        z_1 = Vsp(z_base_1,z_species_1)\n",
    "                        z_2 = Vsp(z_base_2,z_species_2)\n",
    "                        #z_1 = encoder_interm_1(z_base_1)\n",
    "                        #z_2 = encoder_interm_2(z_base_2)\n",
    "                        latent_vectors = torch.cat((z_1, z_2), 0)\n",
    "\n",
    "                        Xhat_1 = decoder_1(z_1)\n",
    "                        Xhat_2 = decoder_2(z_2)\n",
    "                        loss_1 = torch.mean(torch.sum((Xhat_1 - data_1)**2,dim=1)) + encoder_1.L2Regularization(model_params['enc_l2_reg']) + decoder_1.L2Regularization(model_params['dec_l2_reg'])\n",
    "                        loss_2 = torch.mean(torch.sum((Xhat_2 - data_2)**2,dim=1)) +encoder_2.L2Regularization(model_params['enc_l2_reg']) + decoder_2.L2Regularization(model_params['dec_l2_reg'])\n",
    "\n",
    "                        silimalityLoss = torch.sum(torch.cdist(latent_vectors, latent_vectors) * pos_mask.float()) / pos_mask.float().sum()\n",
    "                        w1 = latent_vectors.norm(p=2, dim=1, keepdim=True)\n",
    "                        w2 = latent_vectors.norm(p=2, dim=1, keepdim=True)\n",
    "                        cosineLoss = torch.mm(latent_vectors, latent_vectors.t()) / (w1 * w2.t()).clamp(min=1e-6)\n",
    "                        cosineLoss = torch.sum(cosineLoss * pos_mask.float()) / pos_mask.float().sum()\n",
    "\n",
    "                        p_samples = res_un * pos_mask.float()\n",
    "                        q_samples = res_un * neg_mask.float()\n",
    "                        Ep = log_2 - F.softplus(- p_samples)\n",
    "                        Eq = F.softplus(-q_samples) + q_samples - log_2\n",
    "                        Ep = (Ep * pos_mask.float()).sum() / pos_mask.float().sum()\n",
    "                        Eq = (Eq * neg_mask.float()).sum() / neg_mask.float().sum()\n",
    "                        mi_loss = Eq - Ep\n",
    "                        prior = torch.rand_like(latent_base_vectors)\n",
    "                        term_a = torch.log(prior_d(prior)).mean()\n",
    "                        term_b = torch.log(1.0 - prior_d(latent_base_vectors).mean())\n",
    "                        prior_loss = -(term_a + term_b) * model_params['prior_beta']\n",
    "                        \n",
    "                        # Classification loss\n",
    "                        labels = classifier(latent_vectors)\n",
    "                        true_labels = torch.cat((torch.ones(z_1.shape[0]),\n",
    "                            torch.zeros(z_2.shape[0])),0).long().to(device)\n",
    "                        entropy = class_criterion(labels,true_labels)\n",
    "                        _, predicted = torch.max(labels, 1)\n",
    "                        predicted = predicted.cpu().numpy()\n",
    "                        cf_matrix = confusion_matrix(true_labels.cpu().numpy(),predicted)\n",
    "                        tn, fp, fn, tp = cf_matrix.ravel()\n",
    "                        f1_latent = 2*tp/(2*tp+fp+fn)\n",
    "\n",
    "                        # Remove signal from z_basal\n",
    "                        labels_adv = adverse_classifier(latent_base_vectors)\n",
    "                        true_labels = torch.cat((torch.ones(z_base_1.shape[0]),\n",
    "                            torch.zeros(z_base_2.shape[0])),0).long().to(device)\n",
    "                        adv_entropy = class_criterion(labels_adv,true_labels)\n",
    "                        _, predicted = torch.max(labels_adv, 1)\n",
    "                        predicted = predicted.cpu().numpy()\n",
    "                        cf_matrix = confusion_matrix(true_labels.cpu().numpy(),predicted)\n",
    "                        tn, fp, fn, tp = cf_matrix.ravel()\n",
    "                        f1_basal = 2*tp/(2*tp+fp+fn)\n",
    "                        \n",
    "                        loss = loss_1 + loss_2 + model_params[\n",
    "                            'similarity_reg']*silimalityLoss - model_params[\n",
    "                            'cosine_loss'] * cosineLoss + prior_loss + model_params[\n",
    "                            'lambda_mi_loss'] * mi_loss + model_params[\n",
    "                            'reg_classifier'] * entropy - model_params[\n",
    "                            'reg_adv']*adv_entropy +classifier.L2Regularization(model_params[\n",
    "                            'state_class_reg']) +Vsp.Regularization(model_params['v_reg'])\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        pear_1 = pearson_r(Xhat_1.detach(), data_1.detach())\n",
    "                        mse_1 = torch.mean(torch.mean((Xhat_1.detach() - data_1.detach()) ** 2, dim=1))\n",
    "                        pear_2 = pearson_r(Xhat_2.detach(), data_2.detach())\n",
    "                        mse_2 = torch.mean(torch.mean((Xhat_2.detach() - data_2.detach()) ** 2, dim=1))\n",
    "                if model_params['schedule_step_adv'] is not None:\n",
    "                    scheduler_adv.step()\n",
    "                if e>25:\n",
    "                    #print('10 happened')\n",
    "                    scheduler.step()\n",
    "                    if e%250==0 or e==26:\n",
    "                        outString = 'Cell-line : '+cell+', rand_iter {:.0f}/{:.0f}'.format(j + 1, random_iterations)\n",
    "                        outString += ', Split {:.0f}: Epoch={:.0f}/{:.0f}'.format(i + 1, e + 1, NUM_EPOCHS)\n",
    "                        outString += ', pearson_1={:.4f}'.format(pear_1.item())\n",
    "                        outString += ', MSE_1={:.4f}'.format(mse_1.item())\n",
    "                        outString += ', pearson_2={:.4f}'.format(pear_2.item())\n",
    "                        outString += ', MSE_2={:.4f}'.format(mse_2.item())\n",
    "                        outString += ', MI Loss={:.4f}'.format(mi_loss.item())\n",
    "                        outString += ', Prior Loss={:.4f}'.format(prior_loss.item())\n",
    "                        outString += ', Entropy Loss={:.4f}'.format(entropy.item())\n",
    "                        outString += ', Adverse Entropy={:.4f}'.format(adv_entropy.item())\n",
    "                        outString += ', Cosine ={:.4f}'.format(cosineLoss.item())\n",
    "                        outString += ', silimalityLoss ={:.4f}'.format(silimalityLoss.item())\n",
    "                        outString += ', loss={:.4f}'.format(loss.item())\n",
    "                        outString += ', F1 latent={:.4f}'.format(f1_latent)\n",
    "                        outString += ', F1 basal={:.4f}'.format(f1_basal)\n",
    "                        outString += ', F1 basal trained={:.4f}'.format(f1_basal_trained)\n",
    "                        print(outString)\n",
    "            outString = 'Cell-line : '+cell+', rand_iter {:.0f}/{:.0f}'.format(j + 1, random_iterations)\n",
    "            outString += ', Split {:.0f}: Epoch={:.0f}/{:.0f}'.format(i + 1, e + 1, NUM_EPOCHS)\n",
    "            outString += ', pearson_1={:.4f}'.format(pear_1.item())\n",
    "            outString += ', MSE_1={:.4f}'.format(mse_1.item())\n",
    "            outString += ', pearson_2={:.4f}'.format(pear_2.item())\n",
    "            outString += ', MSE_2={:.4f}'.format(mse_2.item())\n",
    "            outString += ', MI Loss={:.4f}'.format(mi_loss.item())\n",
    "            outString += ', Prior Loss={:.4f}'.format(prior_loss.item())\n",
    "            outString += ', Entropy Loss={:.4f}'.format(entropy.item())\n",
    "            outString += ', Adverse Entropy={:.4f}'.format(adv_entropy.item())\n",
    "            outString += ', Cosine ={:.4f}'.format(cosineLoss.item())\n",
    "            outString += ', silimalityLoss ={:.4f}'.format(silimalityLoss.item())\n",
    "            outString += ', loss={:.4f}'.format(loss.item())\n",
    "            outString += ', F1 latent={:.4f}'.format(f1_latent)\n",
    "            outString += ', F1 basal={:.4f}'.format(f1_basal)\n",
    "            outString += ', F1 basal trained={:.4f}'.format(f1_basal_trained)\n",
    "            print(outString)\n",
    "\n",
    "            encoder_1.eval()\n",
    "            decoder_1.eval()\n",
    "            encoder_2.eval()\n",
    "            decoder_2.eval()\n",
    "            prior_d.eval()\n",
    "            local_d.eval()\n",
    "            classifier.eval()\n",
    "            adverse_classifier.eval()\n",
    "            Vsp.eval()\n",
    "            #encoder_interm_1.eval()\n",
    "            #encoder_interm_2.eval()\n",
    "            \n",
    "            print('Validation performance for cell %s for try %s for split %s'%(cell,j+1,i+1))\n",
    "\n",
    "\n",
    "            X_1 = torch.tensor(cmap_val.loc[:,genes_1].values).float().to(device)\n",
    "            X_2 = torch.tensor(cmap_val.loc[:,genes_2].values).float().to(device)\n",
    "            z_species_1 = torch.cat((torch.ones(X_1.shape[0],1),\n",
    "                             torch.zeros(X_1.shape[0],1)),1).to(device)\n",
    "            z_species_2 = torch.cat((torch.zeros(X_2.shape[0],1),\n",
    "                             torch.ones(X_2.shape[0],1)),1).to(device)\n",
    "                    \n",
    "            z_latent_base_1 = encoder_1(X_1)\n",
    "            z_latent_base_2 = encoder_2(X_2)\n",
    "            z_1 = Vsp(z_latent_base_1,z_species_1)\n",
    "            z_2 = Vsp(z_latent_base_2,z_species_2)\n",
    "            #z_1 = encoder_interm_1(z_latent_base_1)\n",
    "            #z_2 = encoder_interm_2(z_latent_base_2)\n",
    "            Xhat_1 = decoder_1(z_1)\n",
    "            Xhat_2 = decoder_2(z_2)\n",
    "            pear_1 = pearson_r(Xhat_1.detach(), X_1.detach())\n",
    "            pear_2 = pearson_r(Xhat_2.detach(), X_2.detach())\n",
    "            valPear_1.append(pear_1.item())\n",
    "            valPear_2.append(pear_2.item())\n",
    "            print('Pearson correlation 1: %s'%pear_1.item())\n",
    "            print('Pearson correlation 2: %s'%pear_2.item())\n",
    "            \n",
    "            # Classification\n",
    "            labels = classifier(torch.cat((z_1, z_2), 0))\n",
    "            true_labels = torch.cat((torch.ones(z_1.shape[0]).view(z_1.shape[0],1),\n",
    "                                torch.zeros(z_2.shape[0]).view(z_2.shape[0],1)),0).long()\n",
    "            _, predicted = torch.max(labels, 1)\n",
    "            predicted = predicted.cpu().numpy()\n",
    "            cf_matrix = confusion_matrix(true_labels.numpy(),predicted)\n",
    "            tn, fp, fn, tp = cf_matrix.ravel()\n",
    "            class_acc = (tp+tn)/predicted.size\n",
    "            f1 = 2*tp/(2*tp+fp+fn)\n",
    "            valF1.append(f1)\n",
    "            valClassAcc.append(class_acc)\n",
    "            print('Classification accuracy: %s'%class_acc)\n",
    "            print('Classification F1 score: %s'%f1)\n",
    "            \n",
    "            z_1 = Vsp(z_latent_base_1,1.-z_species_1)\n",
    "            #z_1 = encoder_interm_2(z_latent_base_1)\n",
    "            x_hat_2_equivalent = decoder_2(z_1).detach()\n",
    "            pearson_2 = pearson_r(x_hat_2_equivalent.detach(), X_2.detach())\n",
    "            print('Pearson correlation 1 to 2: %s'%pearson_2.item())\n",
    "            z_2 = Vsp(z_latent_base_2,1.-z_species_2)\n",
    "            #z_2 = encoder_interm_1(z_latent_base_2)\n",
    "            x_hat_1_equivalent = decoder_1(z_2).detach()\n",
    "            pearson_1 = pearson_r(x_hat_1_equivalent.detach(), X_1.detach())\n",
    "            print('Pearson correlation 2 to 1: %s'%pearson_1.item())\n",
    "            \n",
    "            valPear.append([pearson_2.item(),pearson_1.item()])\n",
    "            \n",
    "            #torch.save(decoder_1,'../results/test_stuff/models_AutoTransOp/'+cell+'/decoder_1_fold%s_iter%s.pt'%(i,j))\n",
    "            #torch.save(decoder_2,'../results/test_stuff/models_AutoTransOp/'+cell+'/decoder_2_fold%s_iter%s.pt'%(i,j))\n",
    "            #torch.save(prior_d,'../results/test_stuff/models_AutoTransOp/'+cell+'/priorDiscr_fold%s_iter%s.pt'%(i,j))\n",
    "            #torch.save(local_d,'../results/test_stuff/models_AutoTransOp/'+cell+'/localDiscr_fold%s_iter%s.pt'%(i,j))\n",
    "            #torch.save(encoder_1,'../results/test_stuff/models_AutoTransOp/'+cell+'/encoder_1_fold%s_iter%s.pt'%(i,j))\n",
    "            #torch.save(encoder_2,'../results/test_stuff/models_AutoTransOp/'+cell+'/encoder_2_fold%s_iter%s.pt'%(i,j))\n",
    "            #torch.save(classifier,'../results/test_stuff/models_AutoTransOp/'+cell+'/classifier_fold%s_iter%s.pt'%(i,j))\n",
    "            #torch.save(Vsp,'../results/test_stuff/models_AutoTransOp/'+cell+'/Vsp_fold%s_iter%s.pt'%(i,j))\n",
    "            #torch.save(adverse_classifier,'../results/test_stuff/models_AutoTransOp/'+cell+'/adverse_classifier_fold%s_iter%s.pt'%(i,j))\n",
    "            #torch.save(encoder_interm_1,'../results/test_stuff/models_AutoTransOp/'+cell+'/encoder_interm_1_fold%s_iter%s.pt'%(i,j))\n",
    "            #torch.save(encoder_interm_2,'../results/test_stuff/models_AutoTransOp/'+cell+'/encoder_interm_2_fold%s_iter%s.pt'%(i,j))\n",
    "            \n",
    "        valPear = np.array(valPear)\n",
    "        #valPear_shuffled = np.array(valPear_shuffled)\n",
    "        df_result = pd.DataFrame({'model_pearson2to1':valPear[:,0],'model_pearson1to2':valPear[:,1],\n",
    "                                  'recon_pear_2':valPear_2 ,'recon_pear_1':valPear_1,\n",
    "                                  'F1':valF1,'Accuracy':valClassAcc})\n",
    "        #df_result_shuffled = pd.DataFrame({'model_pearson2to1':valPear_shuffled[:,0],'model_pearson1to2':valPear_shuffled[:,1],\n",
    "        #                                   'recon_pear_2':valPear_2_shuffled ,'recon_pear_1':valPear_1_shuffled})\n",
    "        df_result['model'] = 'model'\n",
    "        #df_result_shuffled['model'] = 'shuffled'\n",
    "        df_result['set'] = 'validation'\n",
    "        #df_result_shuffled['set'] = 'validation'\n",
    "        #df_result = df_result.append(df_result_shuffled)\n",
    "        \n",
    "        #df_result_controls = pd.DataFrame({'model_pearson2to1':[],'model_pearson1to2':[],\n",
    "        #                                   'recon_pear_2':[] ,'recon_pear_1':[]})\n",
    "        #df_result_controls['model'] = []\n",
    "        #df_result_controls['set'] = []\n",
    "        #if cell not in [\"HUVEC\",\"HELA\",\"ASC\",\"YAPC\"]:\n",
    "        #    valPear_controls_shuffled = np.array(valPear_controls_shuffled)\n",
    "        #    valPear_controls = np.array(valPear_controls)\n",
    "        #    df_result_controls = pd.DataFrame({'model_pearson2to1':valPear_controls[:,0],'model_pearson1to2':valPear_controls[:,1],\n",
    "        #                                   'recon_pear_2':valPear_controls_2 ,'recon_pear_1':valPear_controls_1})\n",
    "        #    df_result_controls_shuffled = pd.DataFrame({'model_pearson2to1':valPear_controls_shuffled[:,0],'model_pearson1to2':valPear_controls_shuffled[:,1],\n",
    "        #                                   'recon_pear_2':valPear_controls_2_shuffled ,'recon_pear_1':valPear_controls_1_shuffled})\n",
    "        #    df_result_controls['model'] = 'model'\n",
    "        #    df_result_controls_shuffled['model'] = 'shuffled'\n",
    "        #    df_result_controls['set'] = 'controls'\n",
    "        #    df_result_controls_shuffled['set'] = 'controls'\n",
    "        #    df_result_controls = df_result_controls.append(df_result_controls_shuffled)\n",
    "        #df_result = df_result.append(df_result_controls)\n",
    "        df_result['cell'] = cell\n",
    "        df_result['iteration'] = j\n",
    "        df_result_all = df_result_all.append(df_result)\n",
    "        #df_result_all.to_csv('../results/test_stuff/translation_results.csv') #SameCellimputationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60977469",
   "metadata": {},
   "source": [
    "# Remember to save df_result_all after all the trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970faf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
